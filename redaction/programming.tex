\chapter{Machine languages}
\label{chap:programming}

After analyzing the discourses of programmers with regards to beautiful code, after highlighting the specific cognitive hurdles and bypasses inherent to software, and after having investigated how aesthetics enable various forms of understanding in associated fields, we now offer a framework for the aesthetics of source code. To do this, this chapter develops on the medium itself of source code beauty: the programming languages. Understanding what they are and how they are used will allow us to highlight two important aspects. First, that there is a tension between human-meaning and machine-meaning, a tension between syntax and semantics. Second, it will allow us to highlight yet another contextual aspect of source code aesthetics—just like natural languages, machine languages also act as linguistic communities.

Once we laid this material groundwork, we propose two approaches to the aesthetic manifestations in program texts. First, we build on a close-reading approach to suggest a perspective of various scales. We will therefore see how aesthetic manifestations exist along a linear axis of vocabulary, syntax and structure. Finally, we will take a step back to the standards established in \ref{chap:ideals} (e.g. clean, elegant, etc.) and show how these create different contexts for aesthetic appreciation.

Ultimately, this chapter continues on our investigation of how programmers establish mental spaces in order to understand a program text. Programming languages therefore act as an interface between a \emph{base space} (the text) and \emph{built space} (the imagination that the readers has of the text), resulting in a functional cognitive model.

\section{Linguistic interfaces}
\label{sec:linguistic-interfaces}

Software is an idea ultimately represented in specific hardware configurations. The immediate medium of this representation, from the programmer's perspective, is the programming language in which the idea is written down. Programming languages have so far been set aside when examining which sensual aspects of source code resulted in what could be deemed a "beautiful" program text. The relationship between semantics (deep-structure)  and its syntactic representation (surface-structure) is framed by programming languages, as they define the legal organization of form.

This section examines the influence of programming languages on the aesthetic manifestations of source code. To do so, we first go over a broad description of programming languages, ending on what makes a programming language expressive. Second, we touch upon the problem of semantics in programming languages, and how they might differ from a human understanding of semantics. We then we assess their fit as an artistic, expressive system by introducing notions to style and idiomaticity in programming language communities. Finally, we highlight a couple of computing-specific concepts which are made explicit by programming language research, and further define the kinds of concepts that are defined and manipulated when writing code.

\subsection{Programming languages}
\label{subsec:programming-languages}

As an introduction to the section, we start by recalling the historical and technical developments of programming languages, relocating them as an interface between hardware and software, before investigating what makes them good from a general, language designer point of view. This will highlight generic qualities such as orthogonality, abstraction and simplicity, which we will then compare to specific implementations.

\subsubsection{History and developments}
\label{subsubsec:history-developments}

A programming language is a strictly-defined set of syntactic rules and symbols for describing instructions to be executed by the processor. The history of programming languages is, in a sense, the history of decoupling the means of creating software from hardware. The earliest programming languages were embedded in hardware itself, such as piano rolls and punched cards for Jacquard looms \citep{sack_software_2019}. Operating on similar principles, the first electric computers—such as the ENIAC, the UNIVAC or the MUC—still required manual re-wiring in order to implement any change in the algorithm being computed. This process then gave way to programming through the stack of cards fed into the machine, a process which nonetheless retained a definite material aspect. It is with the shift to the stored-program model, at the dawn of the 1950s, that the programs could be written, stored, recalled and executed in their electro(-mecha)nical form, essentially freeing the software result from any immediately physical representation.

This tendency to have software gradually separate from hardware saw a parallel in the development of programming languages themselves. Ultimately, any software instruction needs to execute one of the built-in, hardwired instructions of the processor. Also called \emph{machine language}, these instructions set describe the specific implementation of the most common operations executed by a computer (e.g. \lstinline{add, move, read, load}, etc.), and are the oldest and most direct semantic interface to the hardware. While these are represented as binary numbers to the processing unit, a first layer of a family of languages called Assembly, translate those machines instructions into another set of instructions, whose syntax is loosely based on English. Considered today as some of the most low-level code one can write, Assembly languages are machine-dependent, featuring a one-to-one translation from English keywords to the kind of instruction sets known to the processor they are expected to interface with. As such, a program written for a particular architecture of a computer (e.g. x86 or ARM) cannot be executed without any modifications on a another machine.

% add a part about assembly code poems?

The first widely acknoweldged high-level language which allowed for a complete decoupling of hardware and software was FORTRAN\footnote{Even though programming languages such as Plankalkül, Short Code and Autocode were partial proposals of such decouppling before FORTRAN.}. At this point, programmers did not need to care about the specifics of the machine that they were running on anymore, and found more freedom in their exploration of what could be done in writing software, expanding beyond scientific and military applications into the commercial world (see \ref{sec:practice-programmers}). Moving away from hand-crafted and platform-specific Assembly code also implied a certain sense of looseness incompatible with the extension of its application domain. As such, FORTRAN\footnote{Literally meaning FORmula TRANslation, thus making clear its role as a mediator.}, and the subsquent COBOL, Lisp and ALGOL 58 also started being concerned with the specific definition of their syntax in a non-ambiguous manner to ensure reliability. Using Backus-Naur Form notation, it became possible to formalize their syntactic rules in order to prevent any unexpected behaviour and support rigorous reasoning for the implementation and research of current and subsequent languages. With such specifications, and with the decoupling from hardware, programming languages became, in a way, context-free.

The context-free grammatical basis for programming allowed for the further development of compilers and interpreters, binary programs which, given a syntactically-valid program text, output their machine code representation. Such a machine-code representation can then be executed by the processor\footnote{The main difference between a compiler and an interpreter is that the compiler parses the whole program text as once, resulting in a binary object, while interpreters parse only one line at a time, which is then immediately executed}. At this point, a defining aspect of programming languages is their theoretical lack of ambiguity. This need for disambiguation was reflected both in the engineering roots of computation\footnote{Punch cards and electrical circuits are ultimately discreete—hole or no hole, voltage or no voltage.} and in their formal mathematic roots notation\footnote{For instance, Plankalkül was based on Frege's \emph{Begriffschrift}, a lineage we've seen in \ref{subsec:knowing-what-how}}, and was a requirement of the further development of functional software engineering.

Nowadays, most programming languages are Turing-complete: that is, their design allows for the implementation of a Turing machine and therefore for the simulation of any possible aspect of computation. This means that any programming language that is Turing-complete is equivalent to any other Turing-complete programming language, creating essentially a chain of equivalency between all programming languages. And yet, programming language history is full of rise and fall of languages, of hypes and dissapointments, of self-claimed beautiful ones and criticized ugly ones, from COBOL to Ada, Delphi and C. This is because, given such a wide, quasi-universal problem set, the decision space requires creative constraints: individual programmers resort to different approaches of writing computational procedures, echoing what Gilles Gaston-Granger undestands as \emph{style}, as a formal way to approach the production and communication of aesthetic, linguistic and scientific works \citep{granger_essai_1988}. We have already seen one difference in approaching the domain of computation: compilation vs. interpretation. While the input and outputs are the same \footnote{a program text goes in, and machine code comes out}, there are pros and cons\footnote{For instance, a compiled binary does not need an extra runtime to be executed on a machine, but cannot be immediately used on a different architecture than the one it was compiled for.} to each approach, which in turn allows programmers to bestow value judgments on which on they consider better than the other. Ultimately all programming languages need to address these basic components of computation, but they can do it in the way they want.

\begin{itemize}
  \item{\emph{data}: what kinds of basic datatypes are built-in the language, e.g. signed integers, classes}
  \item{\emph{primitive operations}: how can the programmer directly operate on data, e.g. boolean logic, assignments, arithmetic operations}
  \item{\emph{sequence control} :how the flow of the program can be manipulated and constrained, e.g. if, while statements}
  \item{\emph{data control}: how the data can be initialized and assigned, e.g. type-safe vs. type-unsafe}
  \item{\emph{storage management}: how the programming language handles input/output pipelines}
  \item{\emph{operating environment}: how the program can run, e.g. virtual machine or not}
\end{itemize}

This decision to change the way of doing something while retaining the same goal is particularly salient in the emergence of programming paradigms. A programming paradigm is an approach to programming based on a coherent set of principles, sometimes involving mathematical theory, and grouped into families. Some of these concepts include encapsulation and interfaces (in object-oriented programming), pure function and lacks of side effects (in functional programming), or mathematical logic (in declarative programming). Each paradigm supports a set of concepts that makes it the best for a certain kind of problem \citep{vanroy_programming_2012}, these concepts in turn act as stances which influence how to approach, represent and prioritize the computational concepts mentioned above.

Along with programming paradigms, programming languages also present syntactic affordances for engaging with computational concepts. In order to assess how these formal differences relate to similar concepts, and how a value judgment can be made between languages, we first turn to the question of semantics—before the question of how do computers understand, we look at what they understand.

\subsubsection{Machine semantics and human semantics}
\label{subsubsec:machine-semantics-human-semantics}

One of the reasonings behind the formal approach to programming languages, besides the very material machine requirements of a circuit design based on discreete distinctions, is, according to the designers of ALGOL 58, the dissatisfaction with the fact that subtle semantic questions remained unanswered due to a lack of clear description \citep{sethi_programming_1996}. If the goal of a program text is to be syntactically and semantically clear, and if programming languages are syntactically unambiguous, we examine here under what form do semantics exist as computer representations, and what kind of specific semantic issues are at stake when writing program texts. The very requirement for semantic representation in program language design is first and foremost due to the fact that:

\begin{quote}
  The first and most obvious point is that whenever someone writes a program, it is a program about something. \citep{winograd_language_1982}
\end{quote}

A statement which is itself followed by the tension between semantics and syntax. Semantics have the properties of aboutness and directedness (they point towards something external to them), and syntax has the property of (local) consistency and combination (they function as a mostly closed system). Looking at programing languages as applied mathematics, in the sense that it is the art and science of constituting complex systems through the manipulation formal tokens, tokens which in turn represent elements in the world of some kind, we arrive at the issue of defining semantics in strictly computer-understandable terms.

In order to compare human-meaning with machine-meaning, we turn to the work of Terry Winograd and Fernando Flores. In attempting to develop early forms of artificial intelligence in the 1970s, they develop a framework for machine cognition as related to human cognition \citep{winograd_understanding_1986}. In short, they consider meaning as created by a process of active reading, in which the linguistic form enables interpretation, rather than exclusively conveying information. They further state that interpretation happens through \emph{grounding}, essentially contextualizing information in order to interpret it and extract meaning. He identifies three different kinds of grounding: experiential, formal, and social. The \emph{experiential} grounding, in which verification is made by direct observation, related to the role of the senses in the constitution of the conceptual structures that enable our understanding of the world—also known as the material implementation of knowledge. The \emph{formal} grounding relies on logical and logical statements to deduce meaning from previous, given statements that are known. Finally, \emph{social} grounding relies on a community of individuals sharing similar conceptual structures in order to qualify for meaning to be confirmed. Of these three groundings, computers, through programming languages rely on the second.

The reason for the bypassing of experiential and social grounding can be found in one of the foundations of computer science, as well as information science: Claude Shannon's mathematical theory of communication. In it, he postulates the separation of meaning from information, making only the distinction between signal and noise. Only formal manipulation of signal can then reconstitute meaning\footnote{An affordance that is shared with literature, according to Peter Suber\citep{suber_what_1988}}. Indeed, according to Brian Cantwell-Smith, computing is \emph{meaning mechanically realized}, due to the fact that the machine comes from non-mechanical origins\citep{smith_aos_2016}. We think of computers as digital but they can be seen as only the digital implementation of the phenomenon of computation, with its roots in formal logic. It is therefore through formal logic that one can recreate meaning through the exclusive use of the computer.

A computer is a collection of layers, each defining different levels of machines, with different semantic capabilities. First, it is a physical machine, dealing with voltage differences. These voltage differences are then quantized into binary symbols, in order to become manipulable by a logical machine. From this logical machine is built an abstract machine, which uses logical grounding in order to execute specific, pre-determined commands. The interpretation of which commands to execute, however, leaves no room for the kind of semantic room for error that humans exhibits (particularly in hermeneutics). It is a strictly defined mapping of an input to an output, whose first manifestation can be found in the symbols table in Turing's seminal paper. The abstract machine, in turn, allows for high-level machines (or, more precisely, high-level languages which can implement any other abstract machine). These languages themselves have linguistic constructs which allow the development of representational schemes for data (i.e. data structures such as \lstinline{structs, lists, tuples, objects}, etc.). Finally, the last frontier, so to speak, is the subject domain: the things that the programmer is talking about and intends to act upon. These are then represented in data structures, manipulated through high-level languages, processed by an abstract machine and executed by a logical machine which turns these representations into voltage variations.

The problem domain is akin to a semantic domain, a specific conceptual place that shares a set of meanings, or a language that holds its meaning, within the given context of this place. And there is only one context which the computer provides: itself. Within this unique context, semantics still hold a place in any programming language textbook, and is addressed regularly in programming language research. Concretely, \emph{semantics in computer programming focuses on how variables and functions should behave} \citep{sethi_programming_1996}. Given the statement \lstinline{l := j + p}, the goal of programming language semantics is to deduce what is the correct way to process such a statement; there will be different ways to do so depending on the value and the type of the \lstinline{j} and \lstinline{p} variables. If they are strings, then the value of \lstinline{j} will be their concatenation. If they are numbers, it will be their addition, and so on.

This problem is called the \emph{use-mention} problem, which requires the reconciliation of the name of entities, tokens in source code, with the entities themselves, composed of a value and a type. The way this is achieved is actually quite similar to how syntax is dealt with. The compiler (or interpreter), after lexical analysis, constructs an abstract syntax tree representation of the statement, separating it, in the above case, in the tokens: \lstinline{l}, \lstinline{:=}, \lstinline{j}, \lstinline{+} and \lstinline{p}. Among these, \lstinline{:=} and \lstinline{+} are considered terminal nodes, or leaves, while the other values still need to be determined. The second pass represents a second abstract syntax tree through a so-called semantic analysis, which then \emph{decorates} the first tree, assigning specific values (attributes) and types to the non-terminal nodes, given the working environment (e.g. production, development, test). This process is called \emph{binding}, as it associates (binds) the name of a variable with its value and its type. Semantics is thus the decoration of parsed ASTs, evaluating attribute—which can be either synthesized or inherited. Since decoration is the addition of a new layer (a semantic layer) on top of a base layer (a syntactic one), but of a similar tree form, this leads to the use of what can be described as a \emph{meta-syntax tree}.

In terms when the values are being bound, there are multiple different binding times, such as language-design time (when the meaning of \lstinline{+} is defined), compile time, linker time, and program-writing time. It is only during the last one of these times, that the programmer inserts their interpretation of a particular meaning (e.g. \lstinline{j := "jouer"}, meaning one of the four possible actions to be taken from the start screen of a hypothetical video game). Such a specific meaning is then shadowed by its literal representation (the five consecutive characters which form the string) and its pre-defined type (\lstinline{strings}, here in Go). This process does show that the meaning of a formal expression can, with significant difficulty and clumsiness, nonetheless be explained; but the conceptual content still eludes the computer, varying from the mundane (e.g. a simple counter) to the almost-esoteric (e.g. a playful activity). Even the most human-beautiful code cannot force the computer to deal with new environments in which meaning has, imperceptibly, changed. Indeed,

\begin{quote}
  In programming languages, variables are truly variable, whereas variables in mathematics are actually constant \citep{wirth_essence_2003}.
\end{quote}

From this perspective, the only thing that the computer does know that the programmer doesn't, and which would "make its life easier", the same way that the programmer's life can be made easier through beautiful code, is how the code is represented in an AST, and where in physical memory is located the data required to give meaning to that tree\citep{stansifer_study_1994}. We might hypothesize that beautiful code, from the computer's perspective, is code which is tailored to its physical architecture, a feat which might only be realistically available when writing in Assembly. Before we turn to how such a code is written by the particular group of humans referred to as hackers, there are nevertheless some concepts in programming which do not have simple meaning for humans, re-iterating the need of aesthetics to make these concepts graspable.

As we've seen with software patterns, what also matters to programming languages is not just their design, but their \emph{situated} use:

\begin{quote}
  It must be a pleasure and a joy to work with a language, at least for the orderly mind. The language is the primary, daily tool. If the programmer cannot love his tool, he cannot love his work, and he cannot identify himself with it. \citep{wirth_essence_2003}
\end{quote}

Indeed, if there is one version of how the computer interprets instructions, it is through programming languages that both form and content, syntax and semantics are made accessible to the programmer. Within computation as a single whole, exist multiple programming languages, designed by humans for humans. Particularly, programming languages differentiate themselves by how they guide the programmer in their reading and writing.

\subsection{Qualities of programming languages}
\label{subsec:qualities-programming-languages}

While programming languages all stem from and relate to a single commonality—Turing-completeness and data processing—, these linguistic interfaces nonetheless offer many approaches to performing computation, including a diversity and reliability of functions characteristic of tools. Since diversity within equivalence supports qualified preference, we can now examine what it is that makes a programming language good—i.e. receive a positive value judgment—before turning to the question of the extent to which a good programming language enables the writing of good program texts.

\subsubsection{Abstraction, simplicity and orthogonality}
\label{subsubsec:abstraction-simplicity-orthogonality}

Every programming language of practical use takes a particular approach to those basic components, sometimes backed by an extended rationale (e.g. ALGOL 68), or sometimes not (e.g. JavaScript). In the case in which one is circumscribed to context-free grammars, it would be possible to optimize a particular language for an objective standard (e.g. compile time, time use, cycles used). And still, as computers exist to solve problems beyond their own technical specifications, such problems are diverse in nature and therefore necessitate different approaches\footnote{Patterns, addressed in \ref{subsec:patterns-structures} are one way that diverse approaches can be applied to diverse problems}. These different approaches to the problem domain are in turn influenced the development of those different paradigms, since a problem domain might have different data representations (e.g. objects, text strings, formal rules, dynamic models, etc.) or data flows (e.g. sequential, parallel, non-deterministic). For instance, two of the early programming languages, FORTRAN and Lisp, addressed to very different problem domains: the accounting needs of businesses and the development of formal rules for artificial intelligence, respectively. One might therefore consider that there are better programming languages than others. Under which conditions could this be true?

What makes a good programming language is a matter which has been discussed amongst computer scientists, at least since the \lstinline{GOTO} statement has been publicly considered harmful. Some of these discussions include both subjective arguments over preferred languages, as well as objective arguments related to performance and ease-of-use. According to Pratt and Zelkowitz:

\begin{quote}
  The difference among programming languages are not quantitative differences in what can be done, by only qualitative differences in how elegantly, easily and effectively things can be done. \citep{pratt_programming_2000}
\end{quote}

As a concrete example, one can turn to Brian Kernighan's discussion of his preferences between the language PASCAL and C \citep{kernighan_why_1981}. Going through the generic features of a programming languages, he comments on the approaches taken by the programming languages on each of these. Declaring his preference for strong typing, which is "telling the truth about data", explicit control flow, cosmetic annoyances and his dislike for an environment in which "considerable pains must be taken to simulate sensible input", he professes his preference for the C language \citep{kernighan_why_1981}, all the while acknowledging that PASCAL can nonetheless be a toy language suitable for teaching\footnote{Thus pointing again the context-dependence of value judgments in programming.}.

While this example reveals that individual preferences for programming languages can be based on objective criteria when compared to what a prototypal language should be able to achieve, Turing-completeness offers an interesting challenge to the Sapir-Whorf hypothesis—if natural languages might only weakly affect the kinds of cognitive structures speakers of those languages can construct, programming languages are claimed to do so to large extents. For instance, Alan Perlis's famous \emph{Epigrams on Programming} mentions that "A language that doesn't affect the way you think about programming, is not worth knowing." \citep{perlis_special_1982}. These differences in the ways of doing illustrates how, in reality, different programming languages are applicable to different domains, and do so through different kinds of notations—different aesthetic features when it comes to realizing the same task.

Of the two programs presented below, the output result is exactly the same, but the aesthetic differences are obvious.

\begin{listing}
  \inputminted{ruby}{./corpus/hello.rb}
  \caption{A terse example of writing a string to an output in Ruby.}
  \label{code:hello-ruby}
\end{listing}

\begin{listing}
  \inputminted{java}{./corpus/hello.java}
  \caption{A verbose approach to writing a string to an output in Java.}
  \label{code:hello-java}
\end{listing}

The code in \ref{code:hello-ruby} is written in Ruby, a language designed by Yukihiro Matsumoto, while the code in \ref{code:hello-java} is written in Java, designed by James Gosling, both in the mid-1990s. While Ruby is dynamically-typed, interpreted, Java is a statically-typed and compiled language, and both include garbage collection and object-orientation. These two snippets are obviously quite dissimilar at first glance\footnote{Indeed, \ref{code:hello-ruby} is also a valid program in Python and Perl, both scripting languages.}.

From a language design perspective, Robert Sebesta suggests three main features of programming languages in order to be considered good: \emph{abstraction}, \emph{simplicity} and \emph{orthogonality} \citep{sebesta_concepts_2018}. From the two snippets, we now explore some of the most important criteria in programming language design, and how they could underpin the writing of good programs.

Abstraction is the ability of the language to allow for the essential idea of a statement to be expressed without being encumbered by specifics which do not relate directly to the matter at hand, or to no matter at all. Abstract programming languages can lead to more succint code, and tend to hide complexity (of the machine, and of the language), from the programmer. For instance, the Java snippet above explicitly states the usage of the \lstinline{System} object, in order to access its \lstinline{out} attribute, and then call its \lstinline{println()} method. While a lot of code here might seem verbose, or superfluous, it is in part due to it being based on an object-oriented paradigm. However, \lstinline{out} object itself might seem to go particularly contrary to the requirement of programming languages to abstract out unnecessary details: \lstinline{println()} is definitely a system call dealing with I/O, and therefore already implicitly relates to the output; one shouldn't have to specify it explicitly. In contrast, Ruby entierly abstracts away the system component of the print call, by taking advantadge of its status as an interpreted language: the runtime already provides such standard features of the language. Printing, in Java, does not abstract the machine, while printing, in Ruby, abstracts it away in order to focus on the actual appearance of the message. Another abstraction is that of the language name itself from the import statements. When we write in Java, we (hopefully) know that we write in Java, and therefore probably assume that the default imports come from the Java ecosystem—there shouldn't be any need to explicitly redeclare it. For instance, \lstinline{System.out.println()} isn't written \lstinline{java.io.System.out.println()}. Meanwhile, the Ruby snippet hides the implicit \lstinline{require ".../lib/ruby/3.1.0"}, allow the programmer to focus, through visual clarity, on the real problem at hand, which the logic of the program being written is supposed to address. In this direction, languages which provide more abstraction (such as Ruby), or which handle errors in an abstract way (such as Perl) tend to allow for greater readability by focusing on the most import tokens, rather than aggregating system-related and operational visual clutter—also called verbosity.

Related to abstraction is the approach to \emph{typing}, the process of specifiying the type of a variable or of a return value (such as integer, string, vector, etc.). A strictly-typed language such as C++ might end up being harder to read because of its verbosity, while a type-free language might be simpler to read and write (at a small-scale), but might not provide guarantees of reliability when executed. The tradeoff here is again between being explicit and safe (because a word cannot usually and intuitively be operated on in a similar way as a floating-point number, or as a list), and being implicit, subtle, and dangerous (such as JavaScript's very liberal understanding of typing). In some instances, typing can usually be inferred by purely aesthetic means: Python's boolean values are capitalized (\lstinline{True, False}) and its difference between string and byte is represented by the use of double-quotes for the former and single-quotes for the latter. In the case above, explicitly having to mention that \lstinline{greeting} is of type \lstinline{String} is again redundant, since it is already hinted at by the double-quotes. Ruby does not force programmers to explicitly declare variable types (they can, if they want to), but in this case they let the computers do the heavy lifting of specifying something that is already obvious to the programmer, through a process called dynamic typing.

A particularly note-worthy example of an elegant solution to the tradeoff between guarantee of functionality (safety) and readability can be found in the Go programming language's handling of error values returned by functions:

\begin{listing}
  \inputminted{go}{./corpus/error_handling.go}
  \caption{Go proposes an elegant way of ignoring errors, with the use of the underscore token.}
  \label{code:error-handling}
\end{listing}

The \lstinline{_} character which we see on the first line is the choice made by Go's designers to force the user to both acknowledge and ignore the potential error value that is returned by executing the external command. This particular character, acting as an empty line, \emph{represents absence}, not cluttering the layout of the source, while reminding subtly of the \emph{potential} of this particular statement to go wrong and crash the program. Abstraction is therefore a tradeoff between explicitly highlighting the computer concern (how to operate practically on some data or statement), and hiding anything but the human concern (whether or not that operation is of immediate concern to the problem at hand at all). As such, languages who offer powerful abstractions tend not to stand in the way of the thinking process of the programmer. This particular example of the way in which Go deals with error-handling is a great example of the designer's explicit stylistic choice. In the words of Niklaus Wirth:

\begin{quote}
  Stylistic arguments may appear to many as irrelevant in a technical environment, because they seem to be merely a matter of taste. I oppose this view, and on the contrary claim that stylistic elements are the most visible parts of a language. They mirror the mind and spirit of the designer very directly, and they are reflected in every program written. \citep{wirth_essence_2003}
\end{quote}

An error is, in a programming language, a unique concept with one or more syntactical incarnations. Orthogonality is the affordance for a language to offer a small set of simple syntactics constructs which can be recombined in order to achieve greater complexity, while remaining independent from each other. A direct consequence of such a feature is the ease with which the programmer can familiarize themselves with the number of constructs in the language, and therefore their ease in using them without resorting to the language's reference, or external program texts under the form of packages, libraries, etc. The orthogonality of a language offers a simple but powerful solution to the complexity of understanding software. Because an orthogonal programming language ensures that there is no unintended side-effect at that each program token's action is independent from each other. The functionality of a statement thus comes not just from the individual keywords, but also from their combination.

For instance, the example of Lisp treats both data and functions in a similar way, essentially allowing the same construct to be recombined in powerful ways, while the Ruby language, and its foundational design choice which makes every type (themselves abstracted away) an object allows for greater creativity, through familiarity, in writing code, making the language itself more habitable, if more uncertain\footnote{The infamous monkey-patching technique of Ruby allows the programmer to even modify standard library functions.}. Orthogonality implies both independence, since all constructs operate distinctly from each other, while remaining related, and cooperation with each other, because their functional restrictions requires that they be used in conjunction with one another. This offers a solution to the cognitive burden of the \emph{non-atomicity} of computer programs, in which data can end up being tangled in a non-linear program execution, and become ungraspable. This unreadability is triggered, not by verbosity, but because of the uncertainty of, and confusion about, the potential side-effects caused by any statement. Such independence in programming constructs in turn presents a kind of \emph{symmetry}—a well-accepted aesthetic feature of any artefact—, in that the use of each of the constructs is similar. This similarity eases the cognitive friction in writing and reading code since an orthogonal language allows the programmer to rely on the fact that everything behaves as stated, without having to keep track of a collection of quirks and arbitrary decisions. For example, the below C code is illegal:

\begin{listing}
  \inputminted{go}{./corpus/illegal_return.c}
  \caption{C syntax sometimes behaves arbitrarily.}
  \label{code:illegal-return}
\end{listing}

The above code is a specific instance of one of those quirks: the fact that C cannot return arrays from functions requires both a deep knowledge of the language implementation and a willingness to accept that this is how things are, even though other languages allow for such a feature. In this case, the language exhibits an un-orthogonal property since the two constructs (\lstinline{return} and \lstinline{int[]}) interact with each other in non-independent ways.

Finally, one of the consequences of such a feature is the shift from computer semantic interpretation (usually connected to strongly-typed languages) to human interpretation (and weakly-typed languages). Non-orthogonality implies that the compiler (as a procedural representation of the language) has the final say in what can be expressed, reifing seemingly arbitrary design choices, and requiring cognitive effort from the programmer to identify these unwanted interactions, while orthogonal languages leave more leeway to the writer in focusing on the interaction of all programming constructs used, rather than on a subset of those interactions which does not relate to the program's intent.

Both of these features, abstraction and orthogonality, ultimately relate to simplicity. As Ryan Stansifer puts it:

\begin{quote}
  Simplicity enters in four guises: uniformity (rules are few and simple), generality (a small number of general functions provide as special cases a host of more specialized functions, orthogonality), familiarity (familiar symbols and usages are adopted whenever possible), and brevity (economy of expression is sought). \citep{stansifer_study_1994}
\end{quote}

The point of a simple programming language is to not stand in the way of the program being written, or of the problem being addressed. From a language design perspective, simplicity is achieved by letting the programmer do more (or as much) with less. This means that the set of syntactical tokens exposed to the writer and reader combine in sufficient ways to enable desired expressiveness, and thus relating back to orthogonality\footnote{James Rumbaugh describes his conception of simplicity in designing the UML language as such: "\emph{If you constantly are faced with four or five alternate ways to model a straightforward situation, it isn't simple}" \citep{biancuzzi_masterminds_2009}}.

Moving away from broad language design, and more specific applications, the goal of simplicity is also achieved by having accurate conceptual mappings between computer expression semantics and human semantics (refer to \ref{subsec:psychology-programming} for a discussion of mappings). If one is to write a program related to an interactive fiction in which sentences are being input and output in C, then the apparently simple data structure \lstinline{char} of the language reveals itself to be cumbersone and complex when each word and the sentence that the programmer wants to deal with must be present not as setences nor words, but as series of \lstinline{char}\footnote{Hence the origin of the name of the data type \lstinline{string}, as a continuous series of \lstinline{char}, or characters stringed together.}. A simple language does not mean that it is easy \footnote{Perhaps the simplest language of all being lambda-calculus, is far from an easy construct to grasp, just like the game of Go of which it is said that it is simple to learning, but difficult to master}. By making things simple, but not too simple \citep{biancuzzi_masterminds_2009}, it remains a means to an end, akin to any other tool or instrument\footnote{For a further parallel on musical instruments, see Rich Hickey's keynote address at RailsConf 2012 \citep{confreaks_rails_2012}}.

A proper combination of orthogonality, abstraction and simplicity results, once more, in elegance. Mobilizing the architectural domain, the language designer Bruce McLennan further presses the point:

\begin{quote}
  There are other reasons that elegance is relevant to a well-engineered programming language. The programming language is something the professional programmer will live with - even live in. It should feel comfortable and safe, like a well-designed home or office; in this way it can contribute to the quality of the activities that take place within it. Would you work better in an oriental garden or a sweatshop? \citep{mclennan_who_1997}
\end{quote}

Programming languages are thus both tools and environments, but they are, more uniquely, \emph{symbolic}, manipulating and shaping \emph{symbolic} matter. Looking at these languages from a Goodmanian perspective provides a backdrop to examine their communicative and expressive power. From the perspective of the computer, programming languages are unambiguous insofar as any expression or statement will ultimately result in an unambiguous execution by the CPU (if any ambiguity remains, the program crashes). They are also syntactically disjointed (i.e. clearly distinguishable from one another), but not semantically: two programming tokens can have the same effect under different appearances. The use of formal specifications aimed at resolving any possible ambiguity in the syntax of the language in a very clear fashion, but fashionable equivalence can come back as a desire of the language designer. The semantics of programming languages, as we will see below, also aim at being thoroughly disjointed: a variable cannot be of multiple types at the same time. Finally, programming languages are also differentiated systems since no symbol can refer to two things at the same time.

The tension arises when it comes to the criteria of unambiguity, from a human perspective. The most natural-language-like component of programs, the variable and function names, always have the potential of being ambiguous \footnote{For instance, does \lstinline{int numberOfFlowers} refer to the current number of flowers in memory? To the total number of potential of flowers? To a specific kind of number whose denomination is that of a flower?}. We consider this ambiguity a productive opportunity for creativity, and a hindrance for program effectiveness. So, given the qualification of programming languages as symbolic systems, we could expand our short analysis above by inspecting how programming languages allow for program texts which denote, label, represent, etc. in order to further argument how source code has the potential, and has examples, of being an artistic means of expression and comprehension, from a cognitive point of view.

If programming languages are aesthetic symbol systems, then they can allow for expressiveness, first and foremost of computational concepts. It is in the handling of particularly complex concepts that programming languages also differentiate themselves in value.

\subsubsection{Idiosyncratic implementations}
\label{subsubsec:idiosyncracies-implementations}

Software, as an abstract artifact, can be understood at the physical, design and intentional levels\citep{moor_three_1978}. With modern programming languages allowing us to safely ignore the hardware level, it is at the interaction of the design (programming) and intentional (human) level that things get complicated; the question "what does a Turing machine do?" has \lstinline{n+1} answers, \lstinline{1} syntactic answer, and \lstinline{n} semantic ones, based on however many interpretations.

In order to illustrate the expressivity of programming languages, we highlight three programming concepts which are innate to any modern computing environment, and yet relatively complex to deal with for humans: \emph{iterating}, \emph{referencing} and \emph{threading}.

Referencing is a surface-level consequence of the \emph{use-mention} problem referred to above, the separation between a name and its value, with the two being bound together by the address of the physical location in memory. As somewhat independent entities, it is possible to manipulate them separately, with consequences that are not intuitive to grasp. Some programming languages allow for this direct manipulation, through something called \emph{pointer arithmetic}\footnote{For better or worse, C is very liberal with what can be done with pointers.}. Indeed, the possibility to add and substract memory locations independent of the values held in these locations, as well as the ability to do arithmetic operations between an address and its value isn't a process whose meaning comes from a purely experiential or social perspective, but rather exists meaningfully for humans only through logical grounding, by understanding the theoretical architecture of the computer. What also transpires from these operations is another dimension of the non-linearity of programming languages, demanding complex mental models to be constructed and updated to anticipate what the program will ultimately result in when executed. Notation attempts at remediating those issues by offering symbols to represent these differences, such as in \ref{code:references-c}.

\begin{listing}
  \inputminted{c}{./corpus/references.c}
  \caption{Pointers involve a non-straightforward way to reason about values.}
  \label{code:references-c}
\end{listing}

The characters \lstinline{*} and \lstinline{&} are used to signal that one is dealing with a variable of type pointer, and that one is accessing the pointed location of a variable, respectively. Line 2 of the snippet above is an expression called \emph{dereferencing}, a neologism which is perhaps indicative of the lack of existing words for referring\footnote{No pun intended.} to that concept. In turns, this hints at a lack of conventional conceptual structures to which we can map such a phenomenon, showing some of the limits of metaphorical tools to think through concepts.

\begin{listing}
  \inputminted{python}{./corpus/references.rb}
  \caption{Ruby syntax does not allow the programmer to directly manipulate pointers}
  \label{code:references-ruby}
\end{listing}

Meanwhile, in \ref{code:references-ruby}, we see that the two variables are actually referring to the same data. The design decision here is not to allow the programmer to make the difference between a reference and an actual value, and instead prefer that the programmer constructs programs which, on one side, might be less memory-efficient but are, on the other side, easier to read and write, since variable manipulation only ever occurs in one single way—through reference.

Threading is the ability to do multiple things at the same time, yet in parallel. The concept itself is simple, to the point that we take it for granted in modern computer applications since the advent of time-sharing systems (we can have a text editor take input and scan that input for typos at the same time). However, the proper handling of threading when writing and reading software is quite a complex task. This involves the ability to demultiply the behaviour of routines (whose execution is already non-linear) to keep track of what could be going on at any point in the execution of the program, including use and modification of shared resources, the scheduling of thread start and end, as well as synchronization of race conditions (e.g. if two things happen at the same time, which one happens first, such that the consistence of the global state is preserved?). As Edward A. Lee put it:

\begin{quote}
  Although threads seem to be a small step from sequential computation, in fact, they represent a huge step. They discard the most essential and appealing properties of sequential computation: understandability, predictability, and determinism. Threads, as a model of computation, are wildly non-deterministic, and the job of the programmer becomes one of pruning that nondeterminism \citep{lee_problem_2006}.
\end{quote}

Threading shows how the complexity of a deep-structure benefits to be adequately represented in the surface. Once again, aesthetically-satisfying (simple, concise, expressive) notation can help programmers in understanding what is going on in a multi-threaded program, by removing additional cognitive overload generated by verbosity. Different syntax can help allevaite some of this burden, as we can see in comparing \ref{code:threading-c}, written in C, and \ref{code:threading-go}, written in Go.

\begin{listing}
  \inputminted{python}{./corpus/thread.c}
  \caption{Complex way to do threads in C.}
  \label{code:threading-c}
\end{listing}

\begin{listing}
  \inputminted{python}{./corpus/thread.go}
  \caption{Nice way to do threads in Go.}
  \label{code:threading-go}
\end{listing}

Here, we see how the abstraction provided by some language constructs in Go result in a simpler and more expressive program text. In this case, the non-essential properties of the thread are abstracted away from programmer concern. The \emph{double-meaning} embedded in the \lstinline{go} keyword even uses a sensual evokation of moving away (from the main thread) in order to stimulate implicit understanding of what is going on. Meanwhile, the version written in C includes the necessary headers at the top of the file, the explicit type declaration when starting the thread and the additional \lstinline{join()} method call in order to make sure that the parallel thread returns to the main thread, and does not create a memory leak in the program once the main thread exits. While both behaviours are the same, the syntax of Go allows for a cleaner and simpler representation.

Programming languages tend to help programmers solve semantic issues in the problem domain through elegant syntactical means while reducing unnecessary interactions with the underlying technical system. Nonetheless, we have seen how languages differ in the ways in which they enable the programmer's access to and manipulation of computational actions. Beyond a language designer's perspective, there also exists a social influence on how a source code should be written according to its linguistic community.

\subsection{Styles and idioms in programming}
\label{subsec:style-idioms-programming}

Concrete use of programming languages operate on a different level of formality: if programming paradigms are top-down strategies specified by the language designers, they are also complemented by the bottom-up tactics of softare developers. Such practices crystallize, for instance, in \emph{idiomatic writing}. Idiomaticity refers, in traditional linguistics, to the realized way in which a given language is used, in contrast with its possible, syntactically-correct and semantically-equivalent, alternatives. For instance, it is idiomatic to say "The hungry dog" in English, but not "The hungered dog" (a correct sentence, whose equivalent is idiomatic in French and German). It therefore refers to the way in which a language is a social, experiential construct, relying on intersubjective communication \citep{voloshinov_marxism_1986}. Idiomaticity is therefore not a purely theoretical feature, but first and foremost a social one. This social component in programming languages is therefore related to how one writes a language "properly". In this sense, programming language communities are akin to hobbyists clubs, with their names\footnote{Pythonistas for Python, Rubyists for Ruby, Rustaceans for Rust, Gophers for Go, etc.} meetups, mascots, conferences and inside-jokes. Writing in a particular language can be due to external requirements, but also to personal preference:

\begin{quote}
  I think a programming language should have a philosophy of helping our thinking, and so Ruby's focus is on productivity and the joy of programming. Other programming languages, for example, focus instead on simplicity, performance, or something like that. Each programming language has a different philosophy and design. If you feel comfortable with Ruby's philosophy, that means Ruby is your language. \citep{matsumoto_yukihiro_2019}
\end{quote}

So an idiom in a programming language depends on the social interpretation of the formal programming paradigms\footnote{This is even more present in contemporary programming languages, since paradigms in these languages are often blended and no language is purely single-paradigmatic; for instance, Ruby is a declarative language with functional properties \citep{kidd_why_2005}}. Such an interpretation is also manifested in community-created and community-owned documents, such as \emph{The Zen of Python} \citep{peters_code_1999}.

PEP 20, titled \emph{The Zen of Python}, shows how the philosophy of a programming language relates to the practice of programming in it\footnote{For equivalent guides in other languages see for instance \citep{spencer_ten_1994} or \citep{cheney_practical_2019}}. Without particular explicit directives, it nonetheless highlights \emph{attitudes} that one should keep in mind and exhibit when writing Python code. Such a document sets the mood and the priorities of the Python community at large (being included in its official guidelines in 2004), and highlights a very perspective on the priorities of theoretical language design. For instance, the first Zen is clearly states the priorities of idiomatic Python:

\begin{quote}
  Beautiful is better than ugly. \citep{peters_pep_2004}
\end{quote}

This epigram sets the focus on a specific feature of the code, rather than on a specific implementation. With such a broad statements, it also contributes to strengthening the community bonds by creating shared values as folk knowledge. In practice, writing idiomatic code requires not only the awareness of the community standards around such an idiomaticity, but also knowledge of the language construct themselves which differentiate it from different programming languages. In the case of PEP20 quoted about, one can even include it inside the program text with \lstinline{import this}, showing the tight coupling between abstract statements and concrete code. For instance, in \ref{code:range-operator}, distinct syntactical operators are semantically equivalent but only the second example is considered idiomatic Python, partly because it is \emph{specific} to Python, and because it is more performing than the first example, due to the desire of the developers of Python to encourage idiomaticity (i.e. what they consider good Python to be).

\begin{listing}
  \inputminted{python}{./corpus/range.py}
  \caption{These two range operators are semantically equivalent in Python, but the first is more idiomatic than the second.}
  \label{code:range-operator}
\end{listing}

Beautiful code, then seems to be a function of knowledge, not just of what the intent of the programmer is, but knowledge of the language itself as a social endeavour. We can see in \ref{code:fibonacci} a more complex example of beautiful, because idiomatic, Python code.

\begin{listing}
  \inputminted{python}{./corpus/fibonacci.py}
  \caption{The decorator is the idiotmatic way to calculate the sum of the Fibonacci sequence. \citep{schmitz_what_2015}}
  \label{code:fibonacci}
\end{listing}

This function calculates the Fibonacci sequence (a classic exercise in computer programming), but makes an idiomatic (and clever) use of decorators in Python. The \lstinline{@lru_cache(3)} line caches the last 3 results in the least-recently used order, closely mirroring the fact that the Fibonacci sequence only ever needs to compute the terms n, n-1 and n-2, reducing computational complexity, but at the expense of added complexity for non Pythonistas. Through this, the programmer uses a key, advanced feature of the language in order to make the final program more terse, more precise, and mirroring more faithfully the problem than other implementations, to the detriment of a decrease in readability for non-Pythonistas.

Idiomaticity reflects what the social and aesthetic intent of the language designers and implementers. Notation matters, and designers want to encourage good practices through good notations, assuming that programmers would gravitate towards what is both the most efficient and the best-looking solution.

\begin{quote}
  And it's not hard to "prove" it: If two people write code to solve the same problem and one makes a terrible spaghetti monster in COBOL while the other goes for super-elegant and highly abstracted solution in Haskell, does it really matter to the computer? As long as the two are compiled to the same machine code, the machine does not care. All the clever constructs used, all the elegance, they are there only to guide our intuition about the code. \citep{sustrik_nature_2021}
\end{quote}

Another way to encourage writing good code is through the addition of \emph{syntactic sugar}. Syntactic sugar describes the aesthetic features of the language who are variants of a similar computational feature, and where the only difference between them is their appearance—i.e. visual, semantic shortcuts. The looping examples above are good instances of syntactic sugar, albeit with performance differences. The Ruby language is riddled with syntactic sugar, and highlights how syntactic sugar can "sweeten" the reading process, aiming for more clarity, conciseness, and proximity to natural languages. In Ruby, to access a boolean value on an attribute of an object, one would write it as in any other language. The added syntactic sugar in Ruby comes in the form of the question mark in control flow statements, as shown in \ref{code:ruby-alive}.

\begin{listing}
  \inputminted{python}{./corpus/alive.rb}
  \caption{Ruby features a lot of syntactic sugar.}
  \label{code:ruby-alive}
\end{listing}

There are absolutely no functional differences in the statements above, and the question mark is just here to make the code seem more natural and intuitive to humans. Checking for a boolean (or non-nil value) in an if statement is, in the end, the equivalent of asking a question about that value. Here, Ruby makes that explicit, therefore making it easier to read with the most minimal amount of additional visual noise (i.e. one character).

We've seen how programming languages can be subjected to aesthetic judgment, but those aesthetic criteria are only there to ultimately support the writing of good (i.e. functional and beautiful) code. Such a support exists via design choices (abstraction, orthogonality, simplicity), but also through the practical uses of programming languages, notably in terms of idiomaticity and of syntactic sugar, allowing some languages more readability than others. Like all tools, it is their (knowledgeable) use which matters, rather than their design, and it is the problems that they are used to deal with, and the way in which they are dealt with which ultimately informs whether or not a program text in that language will exhibit aesthetic features.

This concept of appropriateness also relates to material honesty. As seen in \ref{subsubsec:crafting-software}, the fact that a programmer tends to identify their practice with craft implies that they work with tools and materials. Programming languages being their tools, and computation the material, one can extend to the concept of material honesty to the source code \citep{sennett_craftsman_2009}. In this case, working with, and in respect of, the material and tools at hand is a display of excellence in the community of practitioners, and results in an artefact which is in harmony and is well-adapted to the technical environment which allowed it to be. Source code written in accordance with the principles and the affordances of its programming language is therefore more prone to receive a positive aesthetic judgment.

Furthermore, idiomatic writing is accompanied by a language-independnent, but group-dependent feature: that of programming style. Fundamentally, the problem of style might be that "\emph{the practical existence of humanity is absorbed in the struggle between individuality and generality}" \citep{simmel_problem_1991}. Simmel's investigation of the topic focuses on the dichotomy between works of fine art and mass-produced works of applied arts, and he draws a distinction between unique objects displaying the subjectivity of its maker, and  the industrially produced and replicated, and which are only meant to serve practical ends.

As these two kinds of work exist at the opposite extremes of a single continuum, we can insert a third approach: that of the crafted object. It exists in-between, as a repeated display of its maker's subjectivity, destined for active use rather than passive contemplation \citep{sennett_craftsman_2009}. So while style can be seen as a general principle which either mixes with, replaces or displaces individuality, style in programming doesn't stand neatly at either extreme. The work of Gilles-Gaston Granger, and his focus on style as a structuring practice can help to better apprehend style as a relationship between individual taste and structural organization \citep{granger_essai_1988}. Granger posits style in scientific endeavours, which is a component of programming practice, as a mode of knowing at the scale of the group. By abiding by a particular style, the writer and reader can implicitly agree on the fundamental values underpinning a given text, and thus facilitate expectations in further readings of a given program text.

Concretely, programming style exist as dynamic documents,with both social and technical components. On the social side, they are only useful if inconditionally adopted by all members working on a particular code-base, since "\emph{all code in any code-base should look like a single person typed it, no matter how many people contributed.}" \citep{waldron_idiomatic_2020}; in the strict sense, guidelines are therefore reference documents which should provide an answer to the question of what is the preferred way of writing a particular statement (e.g. var vs. let, or camelCase vs. snake\_case). Beyond aesthetic preferences aimed at optimizing the clarity of a given source code, style guides also include a technical component which aims at reducing programming errors by catching erroneous patterns in a given codebase (e.g. variable declaration before intialization, loose reference to the function-calling context).

Programming style also exhibits the particular property that it is not just enforced by convention, but also by computational procedure: linters and formatters are particular software whose main function is to formally rearrange the appearance of lines of code according to some preset rules. This constitutes an additional socio-technical context which further enmeshes human writing and machine writing \citep{depaz_discursive_2022}.

% language design \url{https://dl.acm.org/doi/10.1145/390016.808420}, \url{http://rigaux.org/language-study/syntax-across-languages/}

% \url{https://pointersgonewild.com/2022/05/23/minimalism-in-programming-language-design/}

\spacer

In conclusion, programming languages, as a symbol systems subject to aesthetic judgment, are an important factor in allowing for aesthetic properties to emerge during the process of writing program texts. They present affordances for the abstraction and combination of otherwise-complex programming concepts, for the development of familiarity through their idiomatic uses and for ease of readability—to the point that it might become transparent to experienced readers. Yet, one must keep in mind that there is a difference between considering a programming language good or beautiful \emph{in itself}, considering the quality of the programs written related to the programming language they are written in, in more general aesthetic features. In the next section, we look at some of those aesthetic features which can be transposed across languages.

\section{Spatial aesthetics in program texts}
\label{sec:spatial-aesthetics}

% introduce the two main parts: matters of scale, and particular objects of time and space -> chronotopes

\subsection{Matters of scale}
\label{subsec:matters-of-scale}

The discourses of programmers in our corpus do not contain uni-dimensional criteria, but rather criteria which can be applied at multiple levels of reading. Some tend to relate more to the over-arching design of the code examined while others focus on the specific formal features exhibited by a a given token or successions of tokens in a source code snippet. To address this variability of focus, we borrow from John Cayley's distinction between structures, syntaxes and vocabularies \citep{cayley_code_2012}.  Cayley's framework will allow us to take into account an essential aspect of source code: that of scales at which aesthetic judgment operates. From the psychological accounts of understanding source code in \ref{subsec:psychology-programming} to the uses of space in domain-specific aesthetics in \ref{subsec:spatial-literature} or \ref{subsec:beauty-architecture}, one of the specificities of source is the multiple dimensions of its deep structure hidden behind the two-dimensional layout of a text file.

Structure is defined by the relative location of a particular statement within the broader context of the program text, as well as the groupings of particular statements in relation to each other and in relation to the other groups of statements within the program-text, whether it is across the same file, series of files, or a sprawling network of folders and files. This also includes questions of formatting, indenting and linting as purely pattern-based formal arrangements, as seen in \ref{subsec:style-idioms-programming}, since these affect the whole of the program-text.

Syntax concerns the local arrangement of tokens within a statement or a block statement, including control flow, iterators statements, function declarations, etc., which can be referred to as the "building blocks" of a program-text. Syntax also includes language-specific choices—idioms—and generally the type of statements needed to best represent the task required (e.g. using an array or a struct as a particular data structure for representing entities from the problem domain).

Finally, the vocabulary refers to the user-defined elements of the source code, in the form of variable, function, classe and interface names. Source code vocabulary is constituted of both reserved keywords (which the computer "understands" by being explicitly mentioned by the language designers) and user-defined keywords, the single words which the writes defines themselves and which are not known to a reader who would already know the language's keywords. Unlike the two precedent categories, this is therefore the only one where the writer can come up with new tokens, and is the closest to metaphors in traditional literature.

\subsubsection{Structure}
\label{subsubsec:framework-structure}

At the highest-level, the structure of a program-text can be examined at the surface-level and at the deep-level. The criteria for beauty in surface-structure is layout, as the spatial organization of statements, through the use of line breaks and indentations. While serving additional ends towards understanding, proper layout (whether according to stylistic conventions, or deliberately positioning themselves against these conventions) seems to be the first requirement for beautiful code. In terms of aiding understanding, blank space creates semantic groupings which enable the reader to grasp, at a glance, what are the decisive moments \citep{sennett_craftsman_2009} in the code's execution, and presented by some as akin to paragraphs in litterature \citep{matsumoto_treating_2007}. Such groupings also fit Détienne's identification of \emph{beacons} \citep{detienne_software_2001} as visual markers that indicate important actions in the program text, whether these actions can be described in a single line, in a block or, more rarely, in a series of blocks. Any cursory reading of source code always first and foremost judges layout.

This aid to understanding is further highlighted by a deep-structure criteria of \emph{conceptual distancing}; statements that have to do with each other are either located close to each other or, in the case of more complex program texts, are separated in coherent units (such as in folders) and connected by single syntactic expressions, such as \lstinline{import} or \lstinline{use} statements. Such statements establish an intratextual dimension insofar as it acts as an alias for a larger piece of code, following a practice of abstraction and resulting in non-linear readings. As such, visual appearance at the level of the file can reflect the conceptual structure of the code. At the level of the folder(s), that is, at the level of a collection of files located at different levels of nestedness, one can also highlight stylistic agreement or disagreements. In conventional architectures such as the Model-View-Controller, or the use of \lstinline{lib}, \lstinline{bin} or \lstinline{data} folders also act as aesthetic makers establishing the mental space of the programmer ahead of the reading of the actual source code\footnote{An extreme example of this can be seen in the structure of Ruby on Rails applications, famous for its reliance of convention of folder and file naming.}.

Another instance of intratextual interfacing s the \emph{limitation of function arguments}, according to which arguments given to a function should be either few, or grouped under another name. Going back to the structural criterion above of limiting input/output and keeping groups of statements conceputally independent, function arguments solves this requirement at the level of vocabulary, demonstrating in passing the relative porosity of those categories. Indeed, the naming of variables also reveals the pick of \emph{adequate data-structures}, echoing those who claim that the data on which the code operates can never be ignored, and that beautiful code is code which takes into account that data and communicates it, and its mutations, in the clearest, most intelligible, possible way.

Within the file, structural aesthetic criteria are vague enough (relative to folder-level structure) to be open to interpretation by practitioners and is therefore unable to act as a strict normative criteria, but are nonetheless a solid heuristicof the quality of the software. For instance, a program-text should follow the stepdown rule of function declaration rather than the alphabetical rule when writing in a language which doesn't enforce it. As for variable declarations, global variables should all be declared at the beginning of the highest scope to which they belong (e.g. at the beginning of the file), rather than at the closest location of their next use. Program-texts therefore tend to be more aesthetically pleasing when semantic groupings are respected by the human writer (such as global variable declaration) and syntactic groupings are respected by the machine writer (through linting and formatting).

This uncovers the related criteria of \emph{local coherence}: what is next to each other is related to each other. Local coherence reveals what Goodman calls semantic density, in which tokens grouped together obtain a greater denotative power, while remaining open to further modification by inserting modifications within this grouping. Local coherence operates in balance with the undesirable but unavoidable entanglement of code, as proponents of local coherence in source code imply that a beautiful piece of code should not have to rely on input and output (i.e. not be entangled) and therefore be entirely autotelic. Such an assumption runs contrary to the reality of software development as a practice, and as an object embedded in the world, and thus not "usable" by software developers. This balancing issue can be resolved by writing a source code whose code blocks are structured in such a way that they are related to, but not dependent on, each other \footnote{This aesthetic standard can be traced back to what is called the UNIX philosphy: a related set of tools which only do one thing, do it well, and can be combined into more complex structures.}.

As we travel down from structure ot syntax, we can point to a correlate to conceptual distancing in the form of \emph{conceptual symmetry}, according to which that groups of statement which do the same thing should look the same. It then becomes possible to catch a glimpse of patterns, in which readers know what does what according to a brief overview. Conceptual distancing can be further improved by \emph{conceptual uniqueness}, which demands that all the statements that are grouped together only refer to one single action: complex enough to be useful, and simple enough to be graspable. Aesthetically-pleasing code is thus "the code that does the job while using the least amount of different ideas", which implies a linear relationship between the number of lines of code and the amount of conceptual information to be understood\footnote{In software engineering, this is referred to as the DRY principle—Do not Repeat Yourself\citep{martin_clean_2008}}.

Finally, it should be noted that this aesthetic criteria of structure is only valid for a particular class of program texts, texts written by software engineers. In the case of hackers, poets or scientists\footnote{In the case where scientists write toy or educational programs, without relying on software engineering practices, as seen in \ref{subsec:scientists}}, thei program texts are limited in numbers of lines when compared to code bases of, for instance, large open-source projects. As we will see below, in their case, aesthetic code is code which manages to pack the maximum number of ideas in a minimal amount of lines of code, both in obfuscation practices, one-liners, poetic depictions and in demonstrations of algorithmic ideas.

\subsubsection{Syntax}
\label{subsubsec:framework-syntax}

Syntax, as the mid-level group of criteria, deals most explicitly with two important components of the implementation: the algorithm and the programming language. Beautiful syntax seems to denote a conceptual understanding of the tools at hands to solve a particular problem, and implies an expertise (i.e. both a knowing-what and a knowing-how, in Polanyi's terms \citep{polanyi_knowing_1969}). Here, we consider both algorithms and languages as tools since they are part of the implementation implementation process: a process which turns an idea into form and ensures that this form is functional, and can thus subsequently be examined for aesthetic purposes. While algorithms exist independently from languages, their aesthetic value in the context of this research cannot be separated from the way they are written, itself affected by the language they are written in. Indeed, most algorithms are expressed first as pseudo-code and then implemented in the language that is most suited to a variety of factors (speed, familiarity of the author, suitability of the syntax, nature of the intended audience); this seems to be a contemporary version of the 1950s, when computer scientists would devise those algorithms through pencil and paper, and then leave their implementation at the hands of entirely different individuals—computers \citep{chun_software_2005}.

Beautiful syntax in code responds to this limitation. It resolves the tension between clarity and complexity, with the aim to minimize the number of lines of code, while maximizing both the conceptual implications and the specific affordances for modification. Since algorithms must be implemented in a certain context, with a certain language, it is the task of the writer to best do so with respect to the language that they are currently working in. In this case, knowledge of the language-as-tool and its relevant application makes beautiful syntax an \emph{idiomatic syntax} (see \ref{subsec:style-idioms-programming} above). This involves knowing the possibilities that a given language offers and, in the spirit of the craftsmanship ethos noted previously, working with the language rather than against it. These sets of aesthetic criteria thus become dependent on the syntactical context of the language, itself dependent on its suitability for the problem at hand , and can only be established with regards to each languages. Specifically, this involves knowing which keywords should traditionally not be used, such as \lstinline{unless} in perl, or \lstinline{*} in C, knowing when to use decorators in python, or the spread \lstinline{...} operator in ECMAScript, etc. A common featured shared by these keywords is their tendency to cause more cognitive friction than ease of comprehension.

Here, syntax also follows the idea of conciseness that has been touched upon at the structure-level: a writer can only be concise if they know how the language enables them to be concise. Knowing the algorithms implemented and the problem domain addressed also influence the overall experience of the program text, as the goal is to optimize these three components. The extent to which a syntax is idiomatic and the extent to which the problem domain is accurately represented\footnote{An accurate representation of the problem domain is a representation which enables a direct cognitive mapping between machine-syntactic tokens and human mental models of the entities of the problem domain being processed}, are therefore good indicators of the aesthetic value of a program-text. Conversely, quality syntax is also syntax which refrains from being too idiomatic for the purposes at hand, in software engineering; this is referred to as "clever code" and is generally frowned upon. In the case of hacking code or poetry, cognitive friction is, on the opposite, seen as a positive aesthetic experience. By doing the most with the least, complex hacker code and code poetry enable understandings of polar opposites: hacker syntax displays insight into the highly technical hardware or machine-linguistic environment, while poet syntax offers access to broad human concepts (e.g. of the self, of religion, or history) through a minimal number of lines of code.

A developer who finds that she can best communicate her ideas according to Java will find Java beautiful. A developer who finds that she can best communicate her ideas while writing in Go will find Go beautiful. This state of affairs seems to be part of the reason as to why online platforms are full of endless discussions around the question of which language is better. Ultimately, a syntactical criteria which acts as a response to these discusssions is \emph{consistency}. While there might be specific, personal, preferences as to why one would want to be writing code one way or another (e.g. calling functions on objects rather than calling functions from objects in order to prevent output arguments), this minor increase in aesthetic value through subjective satisfaction—through display of individual skill and personal knowledge—does not compensate for the possible increase in cognitive noise in a collaborative environment. If those different ways of writing are used alternatively in an arbitrary manner, this requires unnecessary mental gymnastics from the reader. In this context, consistency prevails over efficacy, and nonetheless hints at the fact that aesthetics in source code in this context is a game of tradeoffs. Again, hacker and poet aesthetics stand at the opposite: the highly localized and personal function of the program text implies a tolerance for idiosyncracy, since personal knowledge and preference are part of the aesthetic value of the program text.

Beyond the state of syntactic consistency and idiomatic writing, the question of \emph{linguistic reference}, meaning bringing practices from one language into another is yet another aesthetic criteria. Being able to implicitly reference another language in a program-text\footnote{e.g. "this is how we do it now that we have C++, but the current code is written in C, so one can bring in ideas and syntax that are native to C++" or "since Ruby can qualify as a Lisp-like language, one can write lambda functions in an otherwise object-oriented language"}, a code-switching of sorts, can both communicate a deep understanding of not just a language, but an ecosystem of languages while satisfying the purpose of maintaining clarity, at the expense of assuming a certain skill level in the reader. This communicates a feeling of higher-understanding, akin to perceiving all programming languages as ultimately just "tools for the job" and whose purpose is always to get a concept across minds as fully and clearly as possible. However, a misguided intention of switching between two languages, or a mis-handled implementation can propel a program-text further down the gradient of ugliness. The concept communicated would in such a case be obscured by the conflicting idioms, reveal of lack of mastery of the unique aspects of the working language(s), and therefore fail to fulfill the aesthetic criterion of being true to ones materal.

Finally, as we move down to the level of vocabulary, a final syntactic criterion with high aesthetic value is the preference of \emph{natural language reading flow}. For instance, of the two alternatives in Ruby: \lstinline{if people.include? person} vs. \lstinline{if person.in? people}, the second one is to be considered more beautiful than the first one, since it adapts to the reader's habit of reading human languages. However, the essential succintness and clarity of source code is not to be sacrificed for the sake of human-like reading qualities, such as when writers tend to be overly explicit in their writing. Indeed, a definite criteria for ugliness in program-text is verbosity, or useless addition of statements without equivalent addition of functionality or clarity. This is, once again, an example of source code aesthetics being a balance between machine idioms over human idioms—here, the resolution of this balance is the point at which machine idioms are presented as human-readable.

\subsubsection{Vocabulary}
\label{subsubsec:framework-vocabulary}

Vocabulary, as the only component in this framework which directly involves words that can be designed by the writers themselves, is often the most looked at in the literature regarding beautiful code among software developers, as it is the closest to human aesthetics, since their understanding does not require existing knowledge of programming, but also the easiest to assess their functional impact \citep{oliveira_systematic_2022}. Aesthetics here exist at the level of the name and affects most directly the readership of a program-text.

Of the two big problems of programming, the most frequent one is naming\footnote{The full statement, that : "\emph{There are only two hard things in Computer Science: cache invalidation and naming things.}" is a piece of folk knowledge generally attributed to Phil Karlton \citep{fowler_twohardthings_2009}}. One reason as to why that is might be that naming is an inherently social activity, because a name is an utterance which only makes sense when done in the expectation of someone else's comprehension of that name \citep{voloshinov_marxism_1986}. This is supported by the fact that the process of creating a variable or function name on one's own is often more time-consuming when done alone, as reported by developers. Naming, furthermore, aims not just at describing, but at capturing the essence of an object, or of a concept. This is a process that is already familiar in literary studies, particularly in the role of poetry in naming the elusive. Here, we remember how Vilém Flusser sees poetry as the briging-forth that which is conceivable but not yet speakable through its essence in order to make it speakable through prose, using the process of naming through poetry in order to allow for its use and function in prose (see \ref{subsec:literary-beauty} for a mention of Flusser's conception of prose and poetry). In this light, good, efficient and beautiful names in code are those who can communicate the essence of the concept that is being communicated, implying both what they are and how they are used, while omitting extraneous details.

% add a paragraph on two things being the same thing in unix v6 lions p.67 Note that the “sleeps” on lines 4182, 4190 are for essentially different reasons, and could be differentiated to good effect by replacing “&ipc” by “&ipc.ip req” on lines 4190 and 4213.

On a purely sensory level (visual and auditory), surface-level aesthetic criteria related to naming are that of \emph{character length} and \emph{pronounceability}. Visually, character length can indicate the relative importance of a named concept within the greater structure of the program-text. Variables with longer names are variables that are more important, demand more cognitive attention, offer greater intelligibility in comparison with shorter variable names, which only need to be "stored in memory" of the reader for a smaller amount of time. Variables and functions with longer names also exist in a broader scope than their counterparts with shorter names, thus re-introducing a component of scale within our existing framework of scale.

Pronounceability, meanwhile, takes into account the basic human action of "speaking into one's head", as an internal dialogue, and therefore participates in the requirement for communicability of source code amongst human readers. For instance, the difference between \lstinline{mnPtCld} and \lstinline{meanPointCloud} both refer to the same entity, and the second provides an easier cognitive access to it at the very minimal expense of a few characters\footnote{This is only true in a context where character count of variable names does not matter}.

Equally visual, but aesthetically pleasing for both typographical and cognitive reasons, is the \emph{casing} of names. Dealing with the constraint that variable names cannot have whitespace characters as part of them, casing has resulted into the establishment of conventions which pre-exists the precise understanding of what a word denotes, by first bringing that word into a category (all-caps denotes a constant, camelCasing denotes a multi-word variable and first-capitalized words indicate classes or interfaces). By using multiple cues (here, typographical, then semantical, as explicited below), casing again helps with understandability and, in this specific instance of casing, there seems to be quantitative evidence for \lstinline{CamelCasing} to facilitate the scanning of a program text \citep{binkley_camelcase_2009}. Again, casing, by its existence first as a convention, implies that it exists within a social community of writers and readers, and acknowledges the mutual belonging of both writer and reader to such a community, and turns the program-text from a readerly text further into a writerly one \citep{barthes_bruissement_1984}.

Following these visual, auditory and typographical criteria, an aesthetically-pleasing vocabulary is a vocabulary which strictly names \emph{functions as verbs and variables as nouns}. Continuing this correspondence between machine language and human language, there is here a clear mapping between syntax and semantics: functions do things and variables are things. If written the other way around, while this would respect the criteria for consistency, functions as nouns and variables as verbs hint at what it is not, are counter-intuitive and ultimately confusing—confusion which brings ugliness.

The noun given to a variable should be a hint towards the concept addressed, and ideally address what it is, how it is used, and why it is present, things that cannot be deduced from the environment of the program text\footnote{For instance, in statically typed languages, one does not include the type of the variable in its name, since it is enforced by the compiler}. Each of these three aims aren't necessarily easily achieved at the same time, but finding one word which, through multiple means, points to the same end, is an aesthetic goal of source code writers and another testimony of elegant writing. A beautiful name is a name which differentiates between value (obvious, decontextualized, and therefore unhelpful) and intention, informing the reader not just about the current use, but also about future possible use, in code that is written or yet to be written. This is particularly salient in the general distaste of the use of magic numbers, as are called pure values, which do not have a semantic label applied to them. We see here a paradox between direct conceptual relationship between a name and what it denotes, and the multiple meanings that it embodies (its description, its desired immediate behaviour, and its purpose).

Indeed, in the community of software developers, variable names should then have a 1:1 mapping with the object or concept they denote, this isn't the case in other communities, whether those that rely on obfuscation, in which confusion becomes beautiful, or in poetic code, in which \emph{double-meaning} brings an additional, different understanding which ultimately enriches the complexity of the reading \citep{knuth_literate_1984}.  Such the contextual nature of source code aesthetics (see \ref{sec:contexts-of-functions} below) proposes a different standard for source code poetry: the layering of meanings is a positive aesthetic trait in the community of code poets. This harnessing of the double-meaning is the easiest way for writers to offer metaphors, and provides an entry point in to the possibility that all source code is itself a practical metaphor for the task—and therefore the problem—at hand. This aesthetic criteria of double-meaning comes from poetry in human languages, in which layered meanings are aesthetically pleasing, because they point to the un-utterable, and as such, perhaps, the sublime\citep{aquilina_computational_2015}.

\subsubsection{Comments}
\label{subsubsec:framework-comments}

Before moving on to another aspect in which the aesthetics of source code involved with spatialization of meaning mechanically-realized, we touch on a specific case of machine languages. Comments in code do not seem to fall clearly in any of the three categories above. By definition ignored by the compiler/interpreter, comments can be erroneous statements which will persist in an otherwise functional codebase, and are therefore not trusted by experienced, professional software practitioners. In this configuration, comments seem to exist as a compensation for a lack of functional aesthetic exchange. By functional aesthetic exchange I mean an exchange in which a skilled writer is able to be understood by a skilled reader with regards to what is being done and how. If any of these conditions fail (the writer isn't skilled enough and relies on comments to explain what is going on and how it is happening, or the reader isn't skilled enough to understand it without comments), then comments are here to remedy to that failure, and therefore are an indicator (but, again, not a proof) of non-beautiful code, specifically because it relies on extraneous devices, that the computer does without. Nonetheless, they represent a locus for social expression, or human creativity—\ref{code:rendering-borders} is an example of such a display of ingenuity and helpful mental scaffolding for understanding the code.

\begin{listing}
  \inputminted{c}{./corpus/nsCSSRenderingBorders.cpp}
  \caption{An example of useful comments complementing the source code in Mozilla's layout engine.}
  \label{code:rendering-borders}
\end{listing}

The situation in which comments seem to be tolerated is when they provide contextual information, therefore (re-)anchoring the code in a broader world. For instance, this is achieved by offering an indication as to why such an action is being taken at a particular moment of the code, called contractual comments, again pointing at the social existence of source code. This particular use of comments seems to bypass the aesthetic criteria of code being self-explanatory, but nonetheless integrates the criteria of code being writable, a piece of code which, by its appearance, invites the reader to contribute to it, to modify it. As such, in an educational setting (from a classroom to an open-source project), comments are welcome, but rarely quoted as criteria for beautiful code in other communities,again indicating that the appreciation of beautiful code requires a certain level of skill.

In conclusion, we have seen that aesthetic standards for source code can be laid out along a logic of scale, from a macro-level of structure all the way to a micro-level of vocabulary, through an appropriate use of syntax. Throughout, the aesthetic principles of consistency, elegance and idiomaticity are recurring concepts against which a value judgment can be given. However, this approach of a linear scale also hints at another dimension: that of the interface between human concepts and machine concepts, as source code aesthetics enhance the communication of separate semantic layers.

\subsection{Semantic layers} %20k
\label{subsec:semantic-layers}

The specificity of source code is that it interfaces two meaning-makers: the human and the machine. While the machine has a very precise, operational definition of meaning (see \ref{subsec:programming-languages} above), programmers tend to mobilise different modalities in order to make sense of the system they are presented with through this textual interface (see \ref{subsec:psychology-programming}). Among those modalities are the resort to literary techniques (in the form of metaphors), to architecture (in the form of pattern-based structural organization), to mathematics (in the form of symbolic elegance) and craft (in the form of material adequacy and reliabilty).

As a formal manifestation implying, in the context of a crafted object, a producer and a receiver, aesthetics can communicate through the establishment of mental spaces. In domains such as mathematics or literature, mental spaces can represent ideas or emotions; within source code, however, they acquire a more functional dimension. As such, they also communicate \emph{states} and \emph{processes}.

Building on our discussion of understanding software in \ref{sec:understanding-computation}, we now highlight concrete instances of complex computational objects interfaced through source code. These interfaces, as we will see, can be arranged in a convoluted, clever, or obfuscated—that, negative—way, or they can be arranged in a clear, elegant and clean—that is, positive—way.

We take three examples to highlight the multiple manifestations of semantic layers at play in source code, operating in different socio-technical contexts, yet all sharing the same properties of using structure, syntax and vocabulary in order to communicate implicitly a relatively complex idea. First, we look at the astract data type called a \emph{semaphore}, and how it operates as the interface between the computational reality of concurrency, and the human associations of traffic, and resorting primarily from the scientific domain. Second, we turn to a fragment of open-source software which uses abstraction and configuration in order to signify modification, in the context of collaborative, read-write texts characteristic of software development. Finally, we discuss a code poem, as an illustration for the role of programming languages and creative metaphors to support a different kind of functional communication, in Goodman's sense of \emph{working}.

Programming can be seen as an act of encryption/decryption across layers, in which human meaning is encrypted in machine language for computational execution, with the possibility for such meaning of being decrypted for study and modification \citep{ledgard_coding_2011}. We argue that this encryption process involves different aesthetic modalities which, in the majority cases, act as a heuristic for writing functionally good code and, conversely, provide keys for decrypting the intent and processes represented in source code, moving across human and machine layers.

Each in their own way, these modalities represent different semantic layers which bridge machine-meaning and human-meaning. We can consider a semantic layer to be an abstraction over relatively disorganized data in order to render it relatively organized, by providing specific reference points which contribute to the establishment of a mental space, based on the computational space of the program. In the words of Peter Neumann:

\begin{quote}
  A challenge in computer system design is that the representation of the functionality at any particular layer of abstraction should exhibit just those characteristics that are essential at that layer, without the clutter of notational obfuscation and unnecessary appearance of underlying complexity. \citep{neumann_beauty_1990}
\end{quote}

\subsubsection{Abstraction and metaphors}
\label{subsubsec:abstraction-metaphors}

An early, and yet constant problem in computer science, is that of concurrency. Concurrency, or the overlapping execution of multiple interacting computational tasks, emerged along with the development of time-sharing and multi-core hardware. From the 1964 development of MULTICS, a time-sharing operating system that multiple users could use at the same time, to the popularization of multi-processor architecture in the early 1980s, computers moved from executing one task for one user at a time, to multiple tasks for multiple users. The issue that arises then is that of shared memory: how can one design a progam in which two parallel operations can access and modify a shared resource, while at the same time guaranteeing the integrity of the data? \footnote{For instance, say two users (Pierre and Justyna) want watch an online video at the same time, and the website wants to keep track of the number of views. If \lstinline{viewCount} is the variable of the number of views, and is equal to \lstinline{2046} before the visit. Parallel execution means that, if Pierre and Justyna view the video at the same time, they might both separately increase the \lstinline{viewCount} from \lstinline{2046} to \lstinline{2047}, rather than one waiting for the other to complete the increase, and end up with a \lstinline{viewCount} value of \lstinline{2048}.}

While this problem arose from hardware development, whether synchronization is of a universal nature—that is, there exists a solution which can be applied to all practical synchronization problems—has been an ongoing research investigation \citep{leppajarvi_pragmatic_2008}. This tension between hardware innovation and fundamental computing problems reflects once again the multiplicity of layers at play, from matter to ideal, in programming practice. 
Specifically for concurrency, it turns out to be quite difficult for human programmer to model of the different actions taking place in parallel, with overlapping consequences on common data. Just like programming languages can nudge their users into safety\footnote{e.g. with types and compile-time checks.}, there are technical systems which can be designed in order to help humans both think through and implement mechanically this thinking. One such system is Edsger Dijkstra's \emph{semaphores}.

Writing in 1965, Dijkstra describes a data type which prevents such issues of simultaneous access to critical data by two threads of a same process. Such data type possesses two behaviours: \lstinline{post} and \lstinline{wait}. When a thread is about to access a critical part of data, it calls \lstinline{wait}, and when it is done, it calls \lstinline{post}. If another thread also calls \lstinline{wait} before accessing the critical part, \lstinline{wait} checks its internal value to see if another thread is currently processing that data. If it is, then it puts the requesting thread to sleep, and waits until \lstinline{post} is called to wake it up \citep{dijkstra_cooperating_1965}. A textbook implementation of such data structure is described in \ref{code:semaphore-pseudocode}.

\begin{listing}
  \inputminted{cpp}{./corpus/semaphore.cpp}
  \caption{A textbook semaphore description in pseudo-code \citep{arpaci_ostep_2018}}
  \label{code:semaphore-pseudocode}
\end{listing}

Such a piece of code is interesting for its use of multifaceted engagement with metaphors, its existence between abstract and concrete and its involvement with functional reliability.

A lot of different introductory textbooks, from Dijkstra's original paper to the Wikipedia article on semaphores, rely on analogies in the problem domains to describe the problems implied by a concurrent use of shared resources. Dijkstra refers to problems such as \emph{the sleeping barber} or \emph{the banker's algorithm} as use-cases that are both unrealistic but mentally graspable \citep{dijkstra_cooperating_1965}, while the Wikipedia entry refers to \emph{the dining philosophers problem} \citep{wikipedia_semaphore_2023}\footnote{A C++ implementation of such a problem can be seen in \citep{arpaci-dusseau_ostepcode_2023}}. In this case, we see a macro-level aesthetic device in the form of storytelling, which introduces the reader to the origins and implications of concurrent use in computing systems.

Then comes the use of the term \emph{semaphore} itself. In its mechanical form, a semaphore is a device which signals information to a running train, such as whether the tracks ahead are blocked or clear, whether the train should stop or proceed at reduced speed, or if they should exercise caution. There are multiple properties from this source domain that are applied to the target domain of programming. First, the property of a continuously running train, whose alternate state is that of waiting, before starting again, and whose state change is dependent on the state change of the semaphore. In the programming context, a thread also assumes a linear continuous execution, and can under certain circumstances be put to sleep, or woken up, by the process. As we get further away from the concept, and closer to the implementation, the aesthetics of the programming expression switches domains, and becomes more fine-grained.

Ultimately, the micro-specific details of the implementation stop making use of metaphors at all and, in doing so, rely on a different kind of representation. The two operations, denoted above \lstinline{wait} and \lstinline{post}, are actually left to implementation details. In Dijkstra's original paper, such operations are denoted \lstinline{P} and \lstinline{V}, and it is still a matter of debate what those letters stand for, due to the author's use of his native Dutch language \citep{wikipedia_semaphore_2023}. Since these appear as arbitrary marks, we argue that their aesthetic properties in communicating the abstract data type of semaphore changes; they take on the appearance of a single letter: one which is very concrete to the machine, and very abstract to the human.

\subsubsection{Openness and transparency}
\label{subsubsec:openness-transparency}

This next example, taken from Adafruit's \lstinline{pi_video_looper}, exhibits interesting features in terms of openness and transparency, hinting at the reader's implied ability to write.

The program text, published by the Adafruit company, is written in Python and is the source code for a video application running on the Raspberry Pi hardware platform. Both the company and the hardware platform it manufactures are strongly rooted in the ethos of open-source, meaning that it is not just meant to be used, but also to be modified by its users. In this context, the \lstinline{pi_video_looper} project is made available on the GitHub platform, which facilitates copying (forking) by other users.

The particular section of the program text whose particular presentation enables understanding for further modiyfing concerns two similar functions, \lstinline{_load_player()} and \lstinline{_load_file_reader()}, in the \lstinline{video_looper.py} text file, reproduced in \ref{code:pi-video-looper}. These two functions are member methods if the \lstinline{VideoLooper} class and return the specific video playback processes (such as VLC media player or OMXplayer) and file reading drivers (such as a USB drive or a network filesystem).

\begin{listing}
  \inputminted{python}{./corpus/pi_video_looper.py}
  \caption{Abstracting hardware specific resources via configuration options in an open-source project. \citep{dicola_pi_2015}}
  \label{code:pi-video-looper}
\end{listing}

To do so, these two methods operate similarly. Based on the current configuration of the running software, they load actual files through Python's \lstinline{importlib} module, and calls an expected method to return an instantiated object. Since it engages directly with modules in the form of files, rather than through pre-registered abstractions, it gives the end user a glimpse into the workings of the source code as latent scripts of plain text, rather than interpreted code. This might be considered confusing, since this is also the only two occurences of the use of such a technique in a file that is 500 lines long.

And yet, this architectural choice enables the reader to grasp a couple of fundamental concepts never made explicit otherwise. First, the use of the \lstinline{_} character prefix for both methods ensure that these are private methods, and therefore are only directly used in the current class, and thus that these are not called in other, invisible places in the rest of the program text. Second, in a program text whose intention is to be user-friendly, given the number of comments and the culture of the organization from which it stems, an explicit unveiling of dynamic module loading signifies the potential for other modules to be loaded, without having to modify the loading function itself. This expresses the feeling of habitability discussed in \ref{subsubsec:compression-habitability}, in that readers are invited, in turn, to write into the text and make it their own—here, to use a different videop playback or file reading system.

Particularly, the source code is written in such a way that there are hints at the existing parts of the computational environment (the configuration file, the method to be called on the module). This presents a structure in which the writer can insert itself without modifying anything that was not meant to be modified. With three lines of code, each of these methods present an elegant interface between the problem domain (e.g. the media player) and the hardware domain (e.g. \lstinline{omx} vs. \lstinline{hello\_video}); revealing this loading of files, the program text never states how to add to the souce, but rather shows that adding a new playback engine is as simple as writing the playback engine in a new file with at least one specific method as an entrypoint (e.g. \lstinline{create_player}), changing the configuration file value for the new filename, without having to touch these functions themselves. Furthemore, by acting as this textual location through which multiple computational processes interact, this is an example of a beacon (see \ref{subsec:psychology-programming} for a discussion of beacons), a organizing a non-linear reading process by establishing signposts from which to proceed.

This abandoning of abstraction, in order to reveal what should be revealed to a reader-as-potential writer, builds on a community ethos of hacking, where the machine's workings are laid bare in order to support unexpected changes by unknown individuals. This textual hint at both multiple realities (i.e. how the playback is actually done, inside the \lstinline{VideoLooper} abstraction) and particular possibilities (i.e. using, or changing it), creates a particularly welcoming space for newcomers.

% state that the code poetry and the hacker code are limited, and stand in contrast to developer code
\subsubsection{Emotions and functionality}
\label{subsubsec:emotions-functionality}

The poem presented in \ref{code:self_inspect} , written in Ruby by Macario Ortega in 2011 and titled \lstinline{self_inspect.rb}, opens up an additional perspective on the relationship between aesthetics and expressivity in source code. Immediately, the layout of the poem is reminiscent both of obfuscated works and of free-verse poetry, such as E.E. Cummings' and Stéphane Mallarmé's works\footnote{Particularly \emph{Un coup de dés jamais n'abolira le hasard.}}. This particular layout highlights the ultimately arbitrary nature of whitespace use in source code formatting: \lstinline{self_inspect.rb} breaks away from the implicit rhythm embraced in \emph{Black Perl}, and links to the topics of the poem (introspection and \emph{unheimlichkeit}) by abandoning what are, ultimately, social conventions, and reorganizing the layout to emphasize both keyword and topic, exemplified in the \lstinline{end} keyword, pushed away at the end of their line.

\begin{listing}
  \inputminted{ruby}{./corpus/self_inspect.rb}
  \caption{A code poem written by Maca in Ruby. \citep{ortega_maca_2011}}
  \label{code:self_inspect}
\end{listing}

The poem presents additional features which operate on another level, halfway between the surface and deep structures of the program text. First, the writer makes expressive use of the syntax of Ruby by involving data types. While \emph{Black Perl} remained evasive about the computer semantics of the variables, such semantics take here an integral part. Two data types, the array and the symbol are used not just exclusively as syntactical necessities (since they don't immediately fulfill any essential purpose), but rather as semantic ones. The use of \lstinline{:me} on line 2 is the only occurence of the first-person pronoun, standing out in a poem littered with references to \lstinline{you}. Symbols, unlike variable names, stand for variable or method names. While \lstinline{you} refers to a (hypothetically-)defined value\footnote{A variable name can represent a value and/or a memory address}, a symbol refers to a variable name, a variable name which is here undefined. Such a reference to a first-person pronoun implies at the same time its ever elusiveness. It is here expressed through this specific syntactic use of this particular data type, while the second-person is referred to through regular variable names, possibly closer to an actual definition. It is a subtlety which doesn't have an immediate equivalent in natural language, and by relying on the concept of reference, hints at an essential \emph{différance} between you and me.

Reinforcing this theme of the elusiveness of the self, maca plays with the ambiguity of the value and type of \lstinline{you} and \lstinline{you_are}, until they are revealed to be arrays. Arrays are basic data structures consisting of sequential values, and representing \lstinline{you} as such suggests the concept of the multiplicity of the self, adding another dimension to the theme of elusiveness. The discomfort of the poem's voice comes from, finally, from this lack of clear definition of who \lstinline{you} is. Using \lstinline{you_are} as an index to select an element of an array, subverts the role suggested by the declarative syntax of \emph{you are}. The index, here, doesn't define anything, and yet always refers to something, because of the assigment of its value to what the lambda expression \lstinline{->} returns. This further complicates the poem's attempt at defining the self, returning the reverse expression \lstinline{you_are[you]}. While such an expression might have clear, even simple, semantics when read out loud from a natural language perspective, knowledge of the programing language reveals that such a way to assign value contributes significantly to the poem's expressive abilities.

A final feature exhibited by the poem is the execution of the procedure. When running the code, the result is an endless output of print statements of "me", since Ruby interprets the last statement of a program as a return value to be printed, as seen in \ref{code:self_inspect_output}.

\begin{listing}
  \inputminted{text}{./corpus/self_inspect.txt}
  \caption{The executed output from \ref{code:self_inspect}}
  \label{code:self_inspect_output}
\end{listing}

% here, we rewrite this part to discuss functionality and its role in source code, and that provides a transition for the next section

The computer execution of the poem provides an additional layer of meaning to our human interpretation. Through the assignment of \lstinline{you_are} in an \lstinline{until} loop, the result is an endless succession of the literal interpretation of the symbol \lstinline{:me}, the actual result of being in discomfort. While we have seen that a symbol only refers to something \emph{else}, the concrete\footnote{Both in terms of actual, and in terms of concrete poetry} output of the poem evokes an insistence of the literal self, exhibiting a different tone than a source in which the presence of the pronoun \emph{you} is clearly dominant. Such a duality of concepts is thus represented in the duality of a concise source and of an extensive output, and is punctuated by the ultimate impossibility of the machine to process the accumulation of these intertwined references to \emph{me} and \emph{you}, resulting in a stack overflow error.

The added depth of meaning from this code poem goes beyond the syntactic and semantic interplay immediately visible when reading the source, as the execution provides a result whose meaning depends on the co-existence of both source and output. Beyond keywords, variable names and data structures, it is also the procedure itself which gains expressive power: a poem initially about \emph{you} results in a humanly infinite, but hardware-bounded, series of \emph{me}\footnote{Another productive comparison could be found in Stein's work, \emph{Rose is a rose is a rose...}}.

\subsection{Between humans and machines}
\label{subsec:humans-machines}

These analyses of program texts above have highlighted some of the aesthetic features of source code which can elicit a aesthetic experience during reading, and therefore offers a concrete example of the semantic layering which we argue is at the core of source code aesthetics. This idea of multiple levels interpretation, at the minimum between human and machine, has also been explored in the literature through different names.

Focusing on the creative uses of code, Camille Paloque-Bergès presents the concept of \emph{double-meaning}. In her work on networked texts, and her analysis of code poetics \citep{paloque-berges_poetique_2009}. She defines it as the affordance provided by the English-like syntax of keywords reserved for programming to act as natural-language signifiers. As we've seen in \emph{Black Perl}, the Perl functions can indeed be interpreted as regular words when the source is read as a human text. Starting from her analysis of \emph{codeworks}, a body of literature centered around a créole language halfway between humanspeak and computerspeak\footnote{See in particular the work of Alan Sondheim and mezangelle}, it can be extended into the aesthetically productive overlap of syntactic realms.

Previous research by Philippe Bootz has also highlighted the concept of the \emph{double-text} in the context of computer poetry, a text which exists both in its prototypal, virtual, imagined form, under its source manifestation, and which exists as an instantiated, realized one \citep{bootz_problem_2005}. However, he asserts that, in its virtual form, "a work has no reality", specifically because  it is not realized. Here again, we encounter the dependence of the source on its realized output, indeed a defining feature of the generative aesthetics of computer poetry. As we've seen in the \lstinline{self_inspect.rb} poem, a work of code poetry can very much exist in its prototypal form, with its output providing only additional meaning, further qualifying the themes laid out in source beforehand. Indeed, the output of that poem would have a drastically diminished semantic richness if the source isn't also read and understood. For this double-meaning to take place, we can say that the sitation is inverted: the output becomes the virtual, imagined text, while the source is the concrete instantiation of the poem.

Second, we draw on Geoff Cox and Alex McLean's concept of \emph{double-coding} \citep{cox_speaking_2013}. According to them, double-coding \emph{"exemplifies the material aspects of code both on a functional and an expressive level"} (p.9). Cox and McLean's work, in a thorough exploration of source code as an expressive medium, focus on the political features of speaking through code, as a subversive praxis. They work on the broad social implications of written and spoken\footnote{Which they conflate with the practice of live-coding} code, rather than exclusively on the specific features of what makes source code expressive in the first place. Double-coding nonetheless helps us identify the unique structural features of programming languages which support this expressivity. As we've briefly investigated, notably through the use of data types such as symbols and arrays in source code poetry, programming languages and their syntax hold within them a specific kind of semantics which hold, for those who are familiar with them and understand them, expressive power, once the data type is understood both in its literal sense, and in its metaphorical one. The succint and relevant use of these linguistic features can thicken the meaning of a poem, bringing into the realm of the thinkable ways to approach metaphysical topics.

Finally, the tight coupling of the source code and the executed result brings up Ian Bogost's concept of \emph{procedural rhetoric} \citep{bogost_rhetoric_2008}. Bogost presents procedures as a novel means of persuasion, along verbal and visual rhetorics. Working within the realm of videogames, he outlines that the design and execution of processes afford particular stances which, in turn, influence a specific worldview, and therefore arguing for the validity of its existence. Further work has shown that source code examination can already represent these procedures, and hence construct a potential dynamic world from the source \citep{tirrell_dumb_2012}. If procedures are expressive, if they can map to particular versions of a world which the player/reader experiences\footnote{Versions of worlds can be explored further through Goodman's \emph{Ways of Worldmaking}}, then it can be said that their textual description can also already persuasive, and elicit both rational and emotional reactions due to their depiction of higher-order concepts (e.g. consumption, urbanism, identity, morality). As its prototypal version, source code acts as the pre-requisite for such a rhetoric, and part of its expressive power lies in the procedures it deploys (whether from value assignment, execution jumps or from its overall paradigms\footnote{e.g. declarative, imperative, functional}). Manifested at the surface level through code, these procedures however run deeper into the conceptual structure of the program text, and such conceptual structures can nonetheless be echoed in the lived experiences of the reader.

We've seen through this section that the expressivity of program texts rely on several aesthetic mechanisms, connected in a spatial way between a metaphorical understanding of humans and a functional understanding of mahines. From layout to double-meaning through variables and procedure names, double-coding and the integration of data types and functional code into a program text and a rhetoric of procedures in their written form, all of these activate the connection between programming concepts and human concepts to bring the unthinkable within the reach of the thinkable. Most importantly, these techniques are deployed differently according to the socio-technical environment in which the program text is being written and read. The next section summarizes these environments, and pays attention to their impact on aesthetic criteria.

\section{Contexts of functions} %25k
\label{sec:contexts-of-functions}

Despite the diversity of metaphors applied to source code aesthetics, from literature and metaphor, we nonetheless maintains a common ground of functionalism. That is, each program-text that we have examined in this work always implies a necessity of being functioning in order to be properly judged at an aesthetic level. This section argues that function acts both as base for value judgment, but also that it depends on socio-technical contexts in which the program text is being presented.

Indeed, even though the aesthetic judgments we have examined are conditional to function, it does not follow that such required function is approached in similar ways in similar contexts. At first, the computer might be the most direct context defining whether or not a program text functions, from a strictly mechanical perspective; but since programs are both doing something, and are about something, we can start to see how social concerns then modulates the technical context in which the function of a program text is assessed. To do so, we first need to examine how the function of an artefact could be defined, before turning to the relationship between source code and function, and concluding on how aesthetics and function relate.

\subsection{Definitions of function}
\label{subsec:definitions-function}

From a computer science perspective, a function is a program unit which produces an output for each input. While there might not be some explicit value given as an output, a function in a computer program is nonetheless an action which has the ability to modify some internal state of the machine—that is, they are \emph{effective} \citep{abelson_structure_1979}, and they are commonly expected to provide a tangible change as a result of their execution. Here, function is therefore understood in the lineage of lambda calculus, the immediate mathematical predecessor to the Turing machine. In lambda calculus, such input and output are expected to be a numerical value. For instance, the function square, given the number 2, provides the number 4. In fact, the technical environment in which source code exists—computers—are expressedly designed in order to support such a definition of function.

In order to fulfill this definition of function, a given program text must be correctly machine-readable. This means that its syntax must be correct, before its semantics can be executed by the machine. Here, we see a first bifurcation: between what the program text does (represented by its syntax), and what it is about (represented by its semantics). The first can be qualified as an effective function, while the second can be qualified as a useful function. All programs examined in this work have an effective function.

Rather than looking at function from an ontological perspective, through which all programs that are syntactically correct satisfy the criteria of function in order to support an aesthetic judgment, one can also look at it from a more practical perspective, that of \emph{utility}. In this case, the functionality of an artefact is assessed on its use, by situated beings facing precise problems, rather than on its essence.

Incidentally, this brings us back to an older conception of beauty as elaborated by Socrates, and as analyzed by Parsons and Carlson \citep{parsons_functional_2012}, as they emphasize the concept of \emph{fitness}. Fitness, here, is the degree to which a collection of features of an artefact minimize the amount of effort or energy spent in order to achieve the goal of a particular user in a given context—that is, to fulfill a function. Specifically, Parsons and Carlson build on this approach by arguing that beauty can be understood as looking fit for function, thus reconciling both appearance and purpose. In their view, aesthetic appreciation can be dependent on the function of an artefact insofar as such fitness can be perceived by the senses \citep{parsons_functional_2012}. Furthermore, while knowledge of function might not be a pre-requisite for aesthetic appreciation, we can nonetheless note that knowledge indeed factors in in aesthetic judgment. This implies that different expert levels will have different appreciations of the same artefact. Moving away from a discreete understanding of function through syntax-correctness (does it function effectively or not?), we can then move towards a more continuous appreciation of how well an artefact functions (is it useful?). If fitness to function can be a principal criteria for aesthetic judgment, the concept function nonetheless remains multifaceted.

For instance, to assess the function of an artefact, one can relate it to the actions that are enabled by its perceptible properties. Such actions can be decided by the designer of the artefact, in which case the a-priori intention defines the function, or it can be defined by the user, suggesting a more pragmatic approach. Developing this action-oriented, rather than ontological, approach to artefacts Houkes and Vermass state that \emph{an artefact function is any role played by an artefact in a use plan that is justified and communicated to prospective users} \citep{houkes_actions_2004}. From this, it follows that the use of an artefact is both the intention of its creator(s) and the action of its user(s), informed by the typology from which such artefact depends\footnote{For instance, the commonly accepted function of a house in architecture, a proof in mathematics or a discourse in litterature.}, communicated to its users. Finally, diversity of function definitions also nonetheless that there is some hierarchy of functions. While it is complicated to point out a single proper use for an artifact, some of those uses can be considered more proper than others, based on the interplay of social agreement, ontological status of the artefact, technical properties and individual intention(s).

% then we give an example of these multiple functions within architecture
As we developed in \ref{subsec:form-function}, architecture is an artistic field where function is of prime importance, a feature which applies to software development when considering architecture as a metaphor for writing (good) code. Sullivan, on his essay on the relationship between form and function, applies the adjectives sincerity, honesty, and authenticity: such terms connotate a certain idea of ontological straightforwardness, rather than adaptation to other factors such as effective use or environmental constraints. In this sense, functionalism poses function as a requirement and from which follows aesthetic value, even though, in practice, the exact function of a building is often contested.

Existing at the overlap of multiple intentions and uses, buildings present a variety of practical functions influencing the aesthetic judgments that are expressed related to it. An example of these varying functions and the accompanying aesthetic perceptions: a library can be judged on how well it conserves the books, on how well it handles sound propagation, on how well it enables the focus of its dwellers, on how well it represents its cultural symbolism, or on the carbon footprint of its construction and use. Each of these will be weighted differently according to whether one takes the perspective of the architect, the client, of the reader, of the employee, or of the passer-by.

To this strict functionalism as a school of thought,  one can answer that the goal of architecture is not simply to design buildings, but to \emph{create a conception of living} \citep{graham_architecture_2000}, embracing a paradigmatic approach to function as art: the aesthetic value of the built artefact depends on the conception of living that the individual bestowing the judgment ascribes to it. In the case of architecture, one might settle the question of aesthetic value of  a building not by stating that it is because is functional, but rather because it is \emph{useful}, involving both the situated use and the situated intent.

Similarly, in the case of literature, the function of a written work is not just to be decipherable by one other than the other. Starting form an extended conception of literature \citep{gefen_extension_2019}, one can look at artefacts such as press releases, novels, poems, and legal codes as fulfilling different functions (such as informing, immersing, evoking or specifying\footnote{Nonetheless, an artefact can function well, and thus be well-judged aesthetically on multiple functions at the same time. The first sentence of the first paragraph of the first article of the German \emph{Grundgesetz}, "Die Würde des Menschen ist unantastbar." \citep{deutschebundestag_gg_2022}, translated as "The dignity of humans is unviolable.", functions both as a fundamental ground for jurisdiction, and as a condensed narrative evokation of the history of the country in the 20\^{th} century.}). A well-functioning novel will be thus be judged on different criteria than a well-functioning legal code, and so will a piece of investigative journalism, even though all will share the assumed requirement for the artefact to be functioning with respect to its ontological type—here, that it is a system of linguistic signs decipherable by others.

Both from a philosophical and from a practical standpoint, aesthetic judgment is not independent from the function of an artefact; here, we consider it as relatively dependent on its fitness to such function. In turn, we have seen that the concept of function itself depends on the socio-technical context from which one poses the aesthetic judgment, involving both human stances and techical properties. After having highlighted the ontological function of source code as embedded in a computational ontology, we then show the other, pragmatic and paradigmatic functions of source code, and develop on how the aesthetic value of program texts are thus related to such functions. 

\subsection{Functions of source code} %8k
\label{subsec:functions-source-code}

Written between human understanding and machine understanding, program texts emerge very quickly form a strictly computational understanding of function (input-process-output) to suggest other possible functions based on the social and technical contexts for interpretation. Rather than being mutually exclusive, we show how the social and the technical mutually influence each other in providing a backdrop for aesthetic judgment through perceived and intended function.

Programming languages have a syntax and a semantics, but they also have a pragmatics—a contextualised purpose within which they are deployed. This concrete function can be one of correctly achieving a task, of achieving it within a particular resource constrain, of demonstrating how a task could be roughly achieved, demonstrating one's knowledge of the technical environment in which the task is executed, or even demonstrating the expressive limitations of such platform. In all of these cases, function as achievement of intended effect remains an essential aspect through which the quality of the program text artifact can be judged.

For instance, achieving a task such as the demonstration of the properties of a language is not the same thing as using such language in the most technically-efficient manner. The listing \ref{code:p5-teaching} shows how the first function declaration is being explicit in its use of conditional statements, and conservative in its use of the \lstinline{function} token for function declaration. These particular aesthetic choices represent the function of this program text: the communication of the basic actions of drawing in, focusing on \lstinline{fill} and \lstinline{ellipse} as points of interest for the reader. Conversely, the second function declaration focuses more on the technical context and technical knowledge of the reader by using the ternary operator as a conditional statement, and by using the \lstinline{let} definition for the function declaration, thus signalling a more technically-oriented function of compressing this color filling operation, for instance to not draw attention on it within the context a larger program, as well as to run on the most recent versions of the ECMAScript standard to which JavaScript conforms.

\begin{listing}
  \inputminted{text}{./corpus/p5.js}
  \caption{Different ways to write a function in different functional contexts, written in JavaScript.}
  \label{code:p5-teaching}
\end{listing}

What is displayed here is therefore judged differently, depending on the intents of the creator and the expectations of the user. While not exclusive, the technical context in which the program text is written, read and executed—the hardware, programming language and development environment—remains both a determining context and one where artistic creativity supports a pluralistic conception of function.

Particularly, hackers (see the description of the community of practice in \ref{subsec:hackers}) display a practice of writing and reading source code which plays with the naïve definition of technical function of achieving in a straightforward manner a standard task. The aesthetic standards of hacking thus displays a valuation of materiality and epistemology, demonstrating understanding through obfuscation. The knowledge of the machine is implied through the exclusivity: being able to do what others do not know how to do.

Practices of hacking tend to deviate from the original, intended function of a given hardware platform or software system, in order to find a new function. For instance, in cases of XSS attacks, in which an input field on a website is exploited not to provide information to the website system, but rather to penetrate and occupy it\footnote{In the case of so-called blackhat hacking, or in specific social contexts such as \emph{Capture The Flag} events.}. From the website administrator's perspective, the function of the website is perverted, and the code which performs such function might be considered as ugly whereas, from the hacker's perspective, the function of the website as a data input is actually sublimed by circumventing arbitrary protections put in place to prevent certain types of data to be injected.

By switching the paradigms of what an artefact can do, or should do, hacking takes on an epistemological role, providing new knowledge about the possibilities of an artefact, and displaying material proof, in the form of an executed output and a program text. Indeed, hacking relies not on the proclamation of skill, but on its display: it is the effective result which testifies to the function of the artefact, which in turn informs aesthetic judgment, rather than the intended or anticipated result.

This epistemological approach, based on the communication of the skill of the hacker which repurposes an artefact also posseses a visual component, by virtue of its execution from the program text at its source: such component of the hacking aesthetic is the \emph{visual tension}, the fact that an object might not look the part, but actually is doing such part—e.g. the graceful but powerful crane on a construction site—is reflected in practices of obfuscation and obscurity. In cases of obfuscated code, being able to hide visually the purpose of a program text while conserving its invsible, technical-functional properties\footnote{For instance, in the cases of Perl one-liners or obfuscted C code} is thus considered a virtue, and suggests a positive aesthetic judgment. 

Hacking allows us to consider the aesthetics of dysfunction: how one can find pleasure in addressing, and then subverting, the original intent of the artefact, or of the concept of the artefact. A further example of this subversive approach can be seen in the design and use of \emph{esolangs}, esoteric programming languages whose sole purpose is to exist as a commentary on both the arbitrariness and the exhaustivity of computational syntax. Rather than being usable in practical situations and thus useful, they rather function as a commentary on the material of source code, displaying the extent to which something else can be a programming language (such as Daniel Temkin's \lstinline{Folders} language, seen in \ref{graphic:folders}, which uses directories in order to perform computational operations). There can be effective function separately from utility, but the extent to which some programs stretch that distance has itself the function of enriching our understanding of the nature of computation.

\begin{figure}
  \includegraphics[width=0.8\textwidth,height=\textheight,keepaspectratio,center]{PureFolders_HelloWorld_explained.png}
  \caption{Implementation of the traditional \lstinline{"Hello, world!"} program in the Folders programming language. \citep{temkin_daniel_2015}}
  \label{graphic:folders}
\end{figure}

Similar to architecture, software can hardly be separated from what it does, and yet fringe cases do exist in order to focus on under-examined aspects of how an artefact is traditionally thought. In architecture, particular structures do escape expected functional assessments in order to provide new understandings and new possibility, as in the construction of Renaissance follies (displaying symbolic value) or the modern pavillion (displaying technical prowess). Neither of these constructions abide by the traditional function of  architecture (sustaining and sheltering life) but, precisely, these are exceptions confirming the rule, and these extreme examples also help to highlight the default standard, often taken for granted.

At the other end of the spectrum, we can consider code poems as the complementary opposite of such material investigations, arguing rather for the human expressiveness of programming languages. Here, the function is not effective—what actions does programming enable—but useful as it enables new, personal understandings of concepts rendered through programming.

The use of a language such as Perl in both hacky one-liners and full-fledged poems concludes our argumentation of how, along with technical environments, the social environment matters by providing a frame of understanding. We have shown both the variety and necessity of functions in the aesthetic judgment of program texts, as they relate on such environments. Furthermore, we have shown that such function can be both material, in the sense of what technology can help us do, and epistemological, in the sense of what the technology can help us think about. We now conclude this chapter with an investigation into this latter part: the relational, cognitive function of aesthetics connecting aesthetics and ethics.

% FUNCTION IN AESTHETICS 8k
\subsection{Function in aesthetics}
\label{subsec:function-aesthetics}

Operating on the understandability of the ideas that are being presented through source code always implies a certain relation. This relation can be seen in the Ruby community and their motto: "\emph{Matz is nice, and so we are nice}", which sets up a particular context for a human-oriented appreciation of code, one whose syntactic properties is focused on human understanding and joyful co-existence rather than machine understanding\footnote{We can also make a parallel with the \lstinline{nice} score of process on UNIX, further pushing this idea of cohabitation, this time from a machine perspective. Each process in a UNIX system has a nice score, which determines how many computing resources it refrains from using, to let others use them.}. The point here is that aesthetic programming, as a pleasing acitvity at the level of the sense and at the level of the intellect is as well a form of altruistic programming and ties back to a moral virtue mentioned in \ref{subsubsec:compression-habitability} \citep{fleetwood-boldt_matz_2020}. This moral dimension is introduced by the function that program texts have, since they have pratical implications and consequences, and are only autotelic at the edges—i.e. in hacking and poetry.

There is thus an effectiveness to source code aesthetics. A program text look nice because we know that its execution going to perform their function well, and that its arrangement will enable us to perform further functions—that is, its affordances signals that our needs are going to be met by its use. Similarly to the heuristic nature of aesthetics in mathematics \ref{subsubsec:beauty-mathematics}, aesthetics come into play both in the writing and reading of source code.

Writing is, in the moment of its doing, a broadly personal act. When a programmer writes some source code, they do so in a somewhat intimate manner: the only functional judges are onself and the machine, while the only aesthetic judge is oneself. Criteria for aesthetic judgment, at this point, include three axes: the accuracy of the action performed once the program is executed, the ability of the program text to express the concept that is being implemented, and the adequacy of this formal arrangement with the problem at hand—that is, the idiomaticity and elegance of the program text as a solution. Indeed, functional entities appear graceful when they are free of features that are extraneous, or irrelevant in relation to their function. This translation of function into appearance in turn depends on the complementary position: reading source code.

Once a program text is written—that is, once an idea has been given form—the process of reading introduces new constraints for an aesthetic judgment. Reading a program text involves a process of decrypting the realized adequacy between intent, form and function. This amounts to identifying the semantic affordances, under the form of structure, syntax and vocabulary used by the writer(s) to communicate the ideal action of the program. Considering aesthetics as the sensory manifestation of a desire of expression, we put here a particular emphasis on the relationality of such expression. The position of the reader always involves an otherness with respect to the position of the writer. Providing an aesthetic judgment from a reader's perspective thus involves establishing the elegance, fitness, and interest of a certain piece of source code. Things are functionally beautiful where their perceptual appearances are altered by our knowledge of their function \citep{parsons_functional_2012}—that is, artefacts are functionally beautiful when we know where to look, and how to look, implying a certain epistemic movement in the reader.

These properties of elegance, fitness and interest of a program text are all related to its function, with such function being a balance between ideal function and implemented function, expectations and reality. In order to establish a connection between form and function, particularly from a reader's perspective, one must first establish what the program text is about, what it does, how it does, and whether these three dimensions are congruent. Therefore, the translation from form to function involves the acquisition and construction of knowledge. As we have seen throughout this thesis, such a knowledge construction takes place through the establishment of mental spaces. The accuracy and habitability of such spaces both elicit aesthetic pleasure and enable further action within the functional context established by the program text. In this configuration, we can see the importance of the role played by aesthetics as enabling the mental processes, and the construction of mental spaces, representing a clear, distinct and particular computational (that is, functional and operating) idea.

Concluding in the \emph{Languages of Art}, Goodman develops on the relationship between art and understanding. Specifically, he compares an artistic attitude, involving an aesthetic experience, with a scientific one:

\begin{quote}
  The difference between art and science is is not that between feeling and fact, intuition and inference, delight and deliberation, synthesis and analysis, sensation and cerebration, concreteness and abstraction, passion and action, mediacy and immediacy, or truth and beauty, but rather a difference in domination of certain specific characteristics of symbols. \citep{goodman_languages_1976}.
\end{quote}

As a crafted technical artifact borrowing from the characteristics of natural language symbol system, and executed by the machine, source code as a medium occupies a hybrid place between art and science. With a genealogy rooted in hard sciences, and with an ontological nature of functionality, it always involves the concept of correctness, a correctness which is always verified through execution. On the other side, the complexity of the computational systems being described, and the uniqueness of the syntax and semantics offered by the medium of source code that is a programming language, require a certain amount of expressiveness found in the use of metaphors to represent concepts from both the problem domain, and from computation itself.

A final specificity of program texts is that there are very often collaborative and open-ended, particularly in the open-source movement, which tends to make all program texts writerly texts, in the sense of Barthes \citep{barthes_bruissement_1984}. This double movement of readers being potential writers and writers being potential readers complicates an already complex matter. Since the audience can become the creator of modified functional technical systems, expressive devices also act as communicative devices, and thus take on a relational dimension. In turn, this relational dimension within a technical environment involves notions of skill and knowledge whenever the understanding of a program text is at stake, notions of pre-existing skill and knowledge which, in turn, vary from one individual to the next. The program text therefore acts as a bridge between the intent of the ideal version of the software, and the mental spaces constructed by a reader.

All source code aesthetics relate to a certain conception of function: either technical function, or social function, and more or less essential to aesthetic judgment. While these two understanding of function further impact the manifestations of source code, these manifestations are not just expressive, but also communicative, aiming at the transmission of concepts from one individual through the use of machine syntax. Indeed, code that is neither functioning for the machine, nor meaningul for a human holds the least possible value amongst different combinations presented above.A program is always a program \emph{about something}, and therefore holds some intentionality, an intentionality which can, in turn, be made pleasantly graspable by a writer to a reader.

In the overwhelming majority of cases of program texts, the expectation is to understand. The recogntion of the existence of the other as a reader and co-author, both a generalized other in the sense that anyone can theoretically read and modified code, but also as a specificied other, in the sense that the other possesses a particular set of skills, knowledge, habits and practices stemming from the diversity of programming communities. This stance, between general and particular, is one that shows the ethical component of an aesthetic practice: recognizing both the similarity and the difference in the other, and communicating with a peer through specific symbol systems.

\spacer

In conclusion, this chapter has argued first that programming languages provide a socio-technical linguistic environment. Acting first as an interface to the computer, programming languages, without overly-determining the practice of programmers or the content of what is being programming, nonetheless influence how it can be said, through idiosyncracies and stylistic devices.

Starting from John Cayley's framework of levels of literary analysis, we then present a layer-based approach to the points in which aesthetic decisions can take place in source code—that is, across structure, syntax and vocabulary. Broadening this approach, we then showed how these different levels involve an engagement with \emph{semantic layers}: between the human reader, the machine reader and the problem domain. A source code with aesthetic value is one which balances syntactic techniques, structural organization and metaphorical choices in order to communicate a socio-technical intent of a functional artefact.

Analyzing this role of function in the aesthetic judgment of source code, we explicited the two main contexts in which source code is written, as a way to further define how that intent can be judged. These, in turn, determine what kind of aesthetic judgment can be bestowed upon a particular program text. As we related to previous debates of the role of function within aesthetic appreciation, we specified the idiosyncratic status of source code as a medium: between technical and social, expressive and communicative, individual and collaborative. If the aesthetics of source code are highly contextual, they are also social, and as such help us highlight the ethical dimension of aesthetics.